{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rearrange(energy_scores, candidate_position_idx, true_position_idx):\n",
    "    tmp = np.array([[x==y for x in candidate_position_idx] for y in true_position_idx]).any(0)\n",
    "    correct = np.where(tmp)[0]\n",
    "    incorrect = np.where(~tmp)[0]\n",
    "    labels = torch.cat((torch.ones(len(correct)), torch.zeros(len(incorrect)))).int()\n",
    "    energy_scores = torch.cat((energy_scores[correct], energy_scores[incorrect]))\n",
    "    return energy_scores, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'a'\n",
    "\n",
    "energy_scores = torch.tensor([2, 1, 3])\n",
    "candidate_position_idx = [('a', 'b'), ('b', 'c'), ('c', 'd')]\n",
    "# (parent, child)\n",
    "node2pos = [('g', 'e'), ('a', 'b')]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True False False]\n"
     ]
    }
   ],
   "source": [
    "batched_energy_scores, labels = rearrange(energy_scores, candidate_position_idx, node2pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "\n",
    "def calculate_ranks_from_distance(all_distances, positive_relations):\n",
    "    \"\"\"\n",
    "    all_distances: a np array\n",
    "    positive_relations: a list of array indices\n",
    "\n",
    "    return a list\n",
    "    \"\"\"\n",
    "    # positive_relation_distance = all_distances[positive_relations]\n",
    "    # negative_relation_distance = np.ma.array(all_distances, mask=False)\n",
    "    # negative_relation_distance.mask[positive_relations] = True\n",
    "    # ranks = list((negative_relation_distance < positive_relation_distance[:, np.newaxis]).sum(axis=1) + 1)\n",
    "    # ranks = list((all_distances < positive_relation_distance[:, np.newaxis]).sum(axis=1) + 1)\n",
    "    ranks = list(np.argsort(np.argsort(all_distances))[positive_relations]+1)\n",
    "    return ranks\n",
    "\n",
    "def obtain_ranks(outputs, targets):\n",
    "    \"\"\" \n",
    "    outputs : tensor of size (batch_size, 1), required_grad = False, model predictions\n",
    "    targets : tensor of size (batch_size, ), required_grad = False, labels\n",
    "        Assume to be of format [1, 0, ..., 0, 1, 0, ..., 0, ..., 0]\n",
    "    mode == 0: rank from distance (smaller is preferred)\n",
    "    mode == 1: rank from similarity (larger is preferred)\n",
    "    \"\"\"\n",
    "    calculate_ranks = calculate_ranks_from_distance\n",
    "    all_ranks = []\n",
    "    prediction = outputs.cpu().numpy().squeeze()\n",
    "    label = targets.cpu().numpy()\n",
    "    sep = np.array([0, 1], dtype=label.dtype)\n",
    "    \n",
    "    # fast way to find subarray indices in a large array, c.f. https://stackoverflow.com/questions/14890216/return-the-indexes-of-a-sub-array-in-an-array\n",
    "    end_indices = [(m.start() // label.itemsize)+1 for m in re.finditer(sep.tostring(), label.tostring())]\n",
    "    end_indices.append(len(label)+1)\n",
    "    start_indices = [0] + end_indices[:-1]\n",
    "    for start_idx, end_idx in zip(start_indices, end_indices):\n",
    "        distances = prediction[start_idx: end_idx]\n",
    "        labels = label[start_idx:end_idx]\n",
    "        positive_relations = list(np.where(labels == 1)[0])\n",
    "        ranks = calculate_ranks(distances, positive_relations)\n",
    "        all_ranks.append(ranks)\n",
    "    return all_ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1763432/4141578937.py:33: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  end_indices = [(m.start() // label.itemsize)+1 for m in re.finditer(sep.tostring(), label.tostring())]\n"
     ]
    }
   ],
   "source": [
    "all_ranks = obtain_ranks(batched_energy_scores, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2]]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def macro_mr(all_ranks):\n",
    "    macro_mr = np.array([np.array(all_rank).mean() for all_rank in all_ranks]).mean()\n",
    "    return macro_mr\n",
    "\n",
    "def micro_mr(all_ranks):\n",
    "    micro_mr = np.array(list(itertools.chain(*all_ranks))).mean()\n",
    "    return micro_mr\n",
    "\n",
    "def hit_at_1(all_ranks):\n",
    "    rank_positions = np.array(list(itertools.chain(*all_ranks)))\n",
    "    hits = np.sum(rank_positions <= 1)\n",
    "    return 1.0 * hits / len(rank_positions)\n",
    "\n",
    "def hit_at_3(all_ranks):\n",
    "    rank_positions = np.array(list(itertools.chain(*all_ranks)))\n",
    "    hits = np.sum(rank_positions <= 3)\n",
    "    return 1.0 * hits / len(rank_positions)\n",
    "\n",
    "def hit_at_5(all_ranks):\n",
    "    rank_positions = np.array(list(itertools.chain(*all_ranks)))\n",
    "    hits = np.sum(rank_positions <= 5)\n",
    "    return 1.0 * hits / len(rank_positions)\n",
    "\n",
    "def hit_at_10(all_ranks):\n",
    "    rank_positions = np.array(list(itertools.chain(*all_ranks)))\n",
    "    hits = np.sum(rank_positions <= 10)\n",
    "    return 1.0 * hits / len(rank_positions)\n",
    "\n",
    "def precision_at_1(all_ranks):\n",
    "    rank_positions = np.array(list(itertools.chain(*all_ranks)))\n",
    "    hits = np.sum(rank_positions <= 1)\n",
    "    return 1.0 * hits / len(all_ranks)\n",
    "\n",
    "def precision_at_3(all_ranks):\n",
    "    rank_positions = np.array(list(itertools.chain(*all_ranks)))\n",
    "    hits = np.sum(rank_positions <= 3)\n",
    "    return 1.0 * hits / (len(all_ranks)*3)\n",
    "\n",
    "def precision_at_5(all_ranks):\n",
    "    rank_positions = np.array(list(itertools.chain(*all_ranks)))\n",
    "    hits = np.sum(rank_positions <= 5)\n",
    "    return 1.0 * hits / (len(all_ranks)*5)\n",
    "\n",
    "def precision_at_10(all_ranks):\n",
    "    rank_positions = np.array(list(itertools.chain(*all_ranks)))\n",
    "    hits = np.sum(rank_positions <= 10)\n",
    "    return 1.0 * hits / (len(all_ranks)*10)\n",
    "\n",
    "def mrr_scaled_10(all_ranks):\n",
    "    \"\"\" Scaled MRR score, check eq. (2) in the PinSAGE paper: https://arxiv.org/pdf/1806.01973.pdf\n",
    "    \"\"\"\n",
    "    rank_positions = np.array(list(itertools.chain(*all_ranks)))\n",
    "    \n",
    "    scaled_rank_positions = np.ceil(rank_positions / 10)\n",
    "    print(scaled_rank_positions, (1.0 / scaled_rank_positions).mean())\n",
    "    return (1.0 / scaled_rank_positions).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mrr_scaled_10(all_ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "test_path = '../data/MAG_CS/test_nodes.pickle'\n",
    "with open(test_path, 'rb') as f:\n",
    "    test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_test = []\n",
    "for child, parents in test:\n",
    "    temp = []\n",
    "    for parent in parents:\n",
    "        temp.append((parent, child))\n",
    "    new_test.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_path = '../../../data/taxonomy/model_outputs/_meta-llama-Llama-2-7b-hfWnet+FT-32bs_8beams_top40k_stohastic_'\n",
    "with open(pred_path, 'rb') as f:\n",
    "    pred = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['reflexive verb, reflexive pronoun, reflexive verb, reflexive, reflexive pronoun, reflexive, reflex',\n",
       "  'reflexive verb, reflexive pronoun, reflexive verb, reflexive, reflexive pronoun, reflexive, reflex'],\n",
       " ['throughput, bandwidth, and latency, throughput, latency, bandwidth, latency, throughput, bandwidth, latency, band',\n",
       "  'throughput, bandwidth, and latency, throughput, latency, bandwidth, latency, throughput, bandwidth, latency, through']]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hypernyms(line):\n",
    "    clean_line = line.strip().replace(\"\\n\", \",\").replace(\"-\", \" \").split(\",\")\n",
    "\n",
    "    res = []\n",
    "    for hyp in clean_line:\n",
    "        if not hyp in (\"\", \" \", \", \", \",\"):\n",
    "            res.append(hyp.lower().strip())\n",
    "\n",
    "    return res\n",
    "new_pred = [elem[0] for elem in pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('elliptic coordinate system, ellipsoidal coordinate system, spherical coordinate system, coordinate system, ellipsoid, cartesian coordinate system, ellipsoid',\n",
       " [('elliptic coordinate system', 'toroidal coordinates'),\n",
       "  ('parabolic coordinates', 'toroidal coordinates')])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx=4\n",
    "new_pred[idx], new_test[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1763432/4141578937.py:33: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  end_indices = [(m.start() // label.itemsize)+1 for m in re.finditer(sep.tostring(), label.tostring())]\n",
      "/tmp/ipykernel_1763432/719630368.py:57: RuntimeWarning: Mean of empty slice.\n",
      "  print(scaled_rank_positions, (1.0 / scaled_rank_positions).mean())\n",
      "/tmp/ipykernel_1763432/719630368.py:58: RuntimeWarning: Mean of empty slice.\n",
      "  return (1.0 / scaled_rank_positions).mean()\n",
      "/tmp/ipykernel_1763432/719630368.py:14: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1.0 * hits / len(rank_positions)\n",
      "/tmp/ipykernel_1763432/719630368.py:24: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1.0 * hits / len(rank_positions)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[1.] 1.0\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[1. 1. 1. 1. 1. 1.] 1.0\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[1. 1. 1. 1.] 1.0\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[1. 1. 1. 1.] 1.0\n",
      "[1. 1.] 1.0\n",
      "[] nan\n",
      "[] nan\n",
      "[1. 1. 1.] 1.0\n",
      "[] nan\n",
      "[1. 2.] 0.75\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[1. 1.] 1.0\n",
      "[1. 1.] 1.0\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[1. 1. 1. 1. 1. 1. 1.] 1.0\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[1. 1.] 1.0\n",
      "[] nan\n",
      "[] nan\n",
      "[1. 1. 1. 1. 1. 1.] 1.0\n",
      "[] nan\n",
      "[] nan\n",
      "[1.] 1.0\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[1.] 1.0\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[1. 1. 1.] 1.0\n",
      "[1. 1.] 1.0\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[1.] 1.0\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[1. 1.] 1.0\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[1.] 1.0\n",
      "[] nan\n",
      "[] nan\n",
      "[1.] 1.0\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[1. 1.] 1.0\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[1. 1. 1. 1.] 1.0\n",
      "[] nan\n",
      "[] nan\n",
      "[1. 1.] 1.0\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[1. 1.] 1.0\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[1. 1. 1. 1. 1.] 1.0\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[1.] 1.0\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[1.] 1.0\n",
      "[] nan\n",
      "[1. 1.] 1.0\n",
      "[] nan\n",
      "[1.] 1.0\n",
      "[] nan\n",
      "[1. 1.] 1.0\n",
      "[1. 1. 1.] 1.0\n",
      "[] nan\n",
      "[1.] 1.0\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[1. 1.] 1.0\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[1.] 1.0\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[1.] 1.0\n",
      "[1. 1. 1. 1. 1. 1.] 1.0\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 2.] 0.9545454545454546\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[1. 1. 1. 1. 1. 1.] 1.0\n",
      "[1. 1. 1.] 1.0\n",
      "[] nan\n",
      "[1. 2.] 0.75\n",
      "[] nan\n",
      "[1. 1.] 1.0\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[] nan\n",
      "[] nan\n",
      "[1. 1.] 1.0\n",
      "[1.] 1.0\n",
      "[] nan\n",
      "[] nan\n",
      "[1.] 1.0\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[1. 1. 1. 1.] 1.0\n",
      "[] nan\n",
      "[] nan\n",
      "[1. 1.] 1.0\n",
      "[] nan\n",
      "[1.] 1.0\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[1. 1.] 1.0\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[1.] 1.0\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[1. 1.] 1.0\n",
      "[1. 1.] 1.0\n",
      "[] nan\n",
      "[] nan\n",
      "[1.] 1.0\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[1. 1. 1. 1. 1. 1.] 1.0\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[1.] 1.0\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[1. 1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[1. 1. 1. 1.] 1.0\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[1. 1. 1. 1.] 1.0\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[1. 1. 1. 1. 1.] 1.0\n",
      "[1.] 1.0\n",
      "[] nan\n",
      "[1. 1.] 1.0\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[1.] 1.0\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[1. 1. 1.] 1.0\n",
      "[1.] 1.0\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[1. 1.] 1.0\n",
      "[] nan\n",
      "[1.] 1.0\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[1. 1.] 1.0\n",
      "[] nan\n",
      "[1.] 1.0\n",
      "[] nan\n",
      "[] nan\n",
      "[1.] 1.0\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[] nan\n",
      "[] nan\n",
      "[1. 1.] 1.0\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[1.] 1.0\n",
      "[1. 1.] 1.0\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[1.] 1.0\n",
      "[] nan\n",
      "[] nan\n",
      "[1. 1. 1. 1. 1. 1.] 1.0\n",
      "[1. 1. 1.] 1.0\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[1. 1. 1.] 1.0\n",
      "[] nan\n",
      "[1. 1. 1. 1. 1. 1.] 1.0\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[1. 1. 1. 1. 1. 1. 1. 1.] 1.0\n",
      "[1.] 1.0\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[1. 1.] 1.0\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[1.] 1.0\n",
      "[1. 1. 1. 1. 1.] 1.0\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[1.] 1.0\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1. 1. 1. 1.] 1.0\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[1. 1. 1.] 1.0\n",
      "[] nan\n",
      "[1. 1. 1. 1. 1.] 1.0\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[1. 1. 1. 1. 1. 1.] 1.0\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[1. 1. 1.] 1.0\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[1. 1. 1. 1. 1.] 1.0\n",
      "[] nan\n",
      "[1. 1.] 1.0\n",
      "[] nan\n",
      "[] nan\n",
      "[1. 1.] 1.0\n",
      "[] nan\n",
      "[1. 1.] 1.0\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[1. 1. 1. 1. 1. 1.] 1.0\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[1.] 1.0\n",
      "[] nan\n",
      "[] nan\n",
      "[1.] 1.0\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[1. 1. 1. 1. 1.] 1.0\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[1. 1.] 1.0\n",
      "[] nan\n",
      "[1.] 1.0\n",
      "[] nan\n",
      "[1. 1. 1.] 1.0\n",
      "[] nan\n",
      "[] nan\n",
      "[1. 1.] 1.0\n",
      "[] nan\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[1. 1.] 1.0\n",
      "[] nan\n",
      "[1. 1. 1. 1. 1.] 1.0\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[1.] 1.0\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[1.] 1.0\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[1.] 1.0\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[1. 1. 1. 1.] 1.0\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[1.] 1.0\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[1. 1.] 1.0\n",
      "[] nan\n",
      "[1. 1. 1. 1. 1.] 1.0\n",
      "[1.] 1.0\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[1. 1. 1.] 1.0\n",
      "[] nan\n",
      "[] nan\n",
      "[1.] 1.0\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[1.] 1.0\n",
      "[] nan\n",
      "[1.] 1.0\n",
      "[] nan\n",
      "[] nan\n",
      "[1. 1. 1. 1. 1. 1.] 1.0\n",
      "[1.] 1.0\n",
      "[] nan\n",
      "[1. 1. 1. 1. 1. 1. 1. 2. 2.] 0.8888888888888888\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[1.] 1.0\n",
      "[] nan\n",
      "[1. 1.] 1.0\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[1. 1.] 1.0\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[1. 1. 1. 1.] 1.0\n",
      "[1. 1.] 1.0\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[1.] 1.0\n",
      "[] nan\n",
      "[] nan\n",
      "[1.] 1.0\n",
      "[1. 1. 1. 1. 1. 1. 1. 1.] 1.0\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[1.] 1.0\n",
      "[1. 1.] 1.0\n",
      "[] nan\n",
      "[1. 1.] 1.0\n",
      "[1. 1. 1. 1. 1. 1.] 1.0\n",
      "[1. 1.] 1.0\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[1. 1. 1. 1. 1. 1. 1.] 1.0\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[1.] 1.0\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[1. 1. 1. 1.] 1.0\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[1.] 1.0\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[1.] 1.0\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[1. 1.] 1.0\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[1. 1. 1. 1.] 1.0\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[1. 2.] 0.75\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[1. 1. 1.] 1.0\n",
      "[] nan\n",
      "[] nan\n",
      "[1.] 1.0\n",
      "[1. 1. 1. 1. 1. 1.] 1.0\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[] nan\n",
      "[1. 1. 1. 1. 1. 1.] 1.0\n",
      "[1. 1. 1. 1. 1. 1.] 1.0\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[1. 1. 1.] 1.0\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[1.] 1.0\n",
      "[1. 1. 1. 1. 1. 1. 1. 1.] 1.0\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[1.] 1.0\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[1. 1.] 1.0\n",
      "[] nan\n",
      "[2.] 0.5\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[1. 1.] 1.0\n",
      "[1. 1.] 1.0\n",
      "[] nan\n",
      "[] nan\n",
      "[1.] 1.0\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[1.] 1.0\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[1. 2.] 0.75\n",
      "[1.] 1.0\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[1. 1. 1. 1. 1. 1.] 1.0\n",
      "[] nan\n",
      "[1. 1.] 1.0\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[1. 1.] 1.0\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 2. 2. 2. 2. 2. 2.] 0.8125\n",
      "[1. 1. 1.] 1.0\n",
      "[1.] 1.0\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[1. 1. 1. 1.] 1.0\n",
      "[] nan\n",
      "[1. 1. 1.] 1.0\n",
      "[1.] 1.0\n",
      "[] nan\n",
      "[1.] 1.0\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[1. 1.] 1.0\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[1. 2.] 0.75\n",
      "[] nan\n",
      "[] nan\n",
      "[1.] 1.0\n",
      "[] nan\n",
      "[1.] 1.0\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[1. 1. 1.] 1.0\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[1. 1. 1. 1. 1.] 1.0\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[1. 1.] 1.0\n",
      "[] nan\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[1. 1.] 1.0\n",
      "[] nan\n",
      "[1. 1.] 1.0\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[1.] 1.0\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[1. 1. 1.] 1.0\n",
      "[1. 1.] 1.0\n",
      "[1.] 1.0\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[1. 1. 1. 1.] 1.0\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[1. 1.] 1.0\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[1. 1.] 1.0\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[] nan\n",
      "[1.] 1.0\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[1.] 1.0\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[1. 1.] 1.0\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[1.] 1.0\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[1.] 1.0\n",
      "[1.] 1.0\n",
      "[1. 1.] 1.0\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[1. 1. 1.] 1.0\n",
      "[1.] 1.0\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[1. 1. 1. 1. 1. 1. 1. 1.] 1.0\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[] nan\n",
      "[1.] 1.0\n",
      "[] nan\n",
      "[] nan\n",
      "[1.] 1.0\n",
      "[1. 1.] 1.0\n",
      "[] nan\n"
     ]
    }
   ],
   "source": [
    "metric_names = {\n",
    "    'mrr': mrr_scaled_10,\n",
    "    'p1': precision_at_1,\n",
    "    'p5': precision_at_5,\n",
    "    'r1': hit_at_1,\n",
    "    'r5': hit_at_5\n",
    "}\n",
    "\n",
    "metrics = {}\n",
    "for name in metric_names.keys():\n",
    "    metrics[name] = []\n",
    "for idx in range(len(new_test)):\n",
    "    hyps = get_hypernyms(new_pred[idx])\n",
    "    gold = new_test[idx]\n",
    "\n",
    "    child = gold[0][1]\n",
    "    new_hyps = [(hyp, child) for hyp in hyps]\n",
    "    scores = torch.arange(len(new_hyps))\n",
    "\n",
    "    batched_energy_scores, labels = rearrange(scores, new_hyps, gold)\n",
    "\n",
    "    all_ranks = obtain_ranks(batched_energy_scores, labels)\n",
    "    for name, func in metric_names.items():\n",
    "        cur_metric = np.nan_to_num(func(all_ranks))\n",
    "        metrics[name].append(cur_metric)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mrr 0.20890593434343435\n",
      "p1 0.153\n",
      "p5 0.07680000000000001\n",
      "r1 0.08827959956709956\n",
      "r5 0.1705392676767677\n"
     ]
    }
   ],
   "source": [
    "for name, v in metrics.items():\n",
    "    print(name, np.mean(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1763432/4141578937.py:33: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  end_indices = [(m.start() // label.itemsize)+1 for m in re.finditer(sep.tostring(), label.tostring())]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
