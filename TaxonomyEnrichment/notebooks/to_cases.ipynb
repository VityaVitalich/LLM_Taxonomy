{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import glob\n",
    "import networkx as nx\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "sys.path.append('../../')\n",
    "from DataConstructor.notebooks.leafer import Leafer\n",
    "\n",
    "\n",
    "\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.read_edgelist(\"../../TaxonomyEnrichment/data/noun/train.edgelist\", delimiter=\"\\t\", create_using=nx.DiGraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "wn = True\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        cycle = nx.find_cycle(G)\n",
    "        print(cycle)\n",
    "        G.remove_edge(*cycle[0])\n",
    "    except:\n",
    "        break\n",
    "\n",
    "if not wn:\n",
    "    new_labels = {}\n",
    "    for node in G.nodes():\n",
    "        new_labels[node] = node + '.n.1'\n",
    "\n",
    "    G_new = nx.relabel_nodes(G, new_labels)\n",
    "\n",
    "    l = Leafer(G_new)\n",
    "else:\n",
    "    l = Leafer(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_hypernym 41363 41363\n"
     ]
    }
   ],
   "source": [
    "train, test = l.split_train_test(\n",
    "    generation_depth=0,  # до какого уровня в топ. сортировке идти\n",
    "    p=0.0,  # вероятность что подходящий случай уйдет в тест\n",
    "    p_divide_leafs=0.5,\n",
    "    # вероятность что листья поделим пополам трейн-тест\n",
    "    # а не засунем целый случай в трейн или в тест\n",
    "    min_to_test_rate=0.5,\n",
    "    # минимальное количество доли вершин которых не было в\n",
    "    # трейне чтобы поделить пополам на трейн-тест\n",
    "    # то есть если 6\\10 вершин были трейне то значит все 10 в трейн\n",
    "    # если 5\\10 были в трейне, то значит оставшиеся можем кинуть в тест\n",
    "    weights=[0.00, 0.0, 0.0, 0.00, 0.00, 1.],\n",
    "    # веса в соответствии\n",
    "    # один ребенок, только листья, не только листья\n",
    "    # триплеты с 2 родителями, триплеты такие что мидл нода имеет\n",
    "    # 1 ребенка, предсказание родителя\n",
    "    #p_parent=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = '../data/noun/test_nodes.pickle'\n",
    "with open(test_path, 'rb') as f:\n",
    "    test_nodes = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([('unconventionality.n.02', ['unorthodoxy.n.03']),\n",
       "  ('awnless_bromegrass.n.01', ['brome.n.01']),\n",
       "  ('slenderness.n.01', ['insufficiency.n.03']),\n",
       "  ('speedskater.n.01', ['ice-skater.n.01']),\n",
       "  ('laminectomy.n.01', ['ablation.n.01'])],\n",
       " [{'children': 'dancing.n.01',\n",
       "   'parents': 'diversion.n.01',\n",
       "   'grandparents': None,\n",
       "   'case': 'predict_hypernym'},\n",
       "  {'children': 'bagel.n.01',\n",
       "   'parents': 'bun.n.01',\n",
       "   'grandparents': None,\n",
       "   'case': 'predict_hypernym'},\n",
       "  {'children': 'shopping_bag.n.01',\n",
       "   'parents': 'bag.n.01',\n",
       "   'grandparents': None,\n",
       "   'case': 'predict_hypernym'},\n",
       "  {'children': 'pteridology.n.01',\n",
       "   'parents': 'botany.n.02',\n",
       "   'grandparents': None,\n",
       "   'case': 'predict_hypernym'},\n",
       "  {'children': 'house_wren.n.01',\n",
       "   'parents': 'wren.n.02',\n",
       "   'grandparents': None,\n",
       "   'case': 'predict_hypernym'}])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_nodes[:5], train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = []\n",
    "\n",
    "for child, parents in test_nodes:\n",
    "    elem = {}\n",
    "    elem[\"children\"] = child\n",
    "    elem[\"grandparents\"] = None\n",
    "    if len(parents) == 1:\n",
    "        elem[\"parents\"] = parents[0]\n",
    "        elem[\"case\"] = \"predict_hypernym\"\n",
    "    else:\n",
    "        elem[\"parents\"] = parents\n",
    "        elem[\"case\"] = \"predict_multiple_hypernyms\"\n",
    "\n",
    "    test.append(elem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'children': 'unconventionality.n.02',\n",
       "  'grandparents': None,\n",
       "  'parents': 'unorthodoxy.n.03',\n",
       "  'case': 'predict_hypernym'},\n",
       " {'children': 'awnless_bromegrass.n.01',\n",
       "  'grandparents': None,\n",
       "  'parents': 'brome.n.01',\n",
       "  'case': 'predict_hypernym'},\n",
       " {'children': 'slenderness.n.01',\n",
       "  'grandparents': None,\n",
       "  'parents': 'insufficiency.n.03',\n",
       "  'case': 'predict_hypernym'},\n",
       " {'children': 'speedskater.n.01',\n",
       "  'grandparents': None,\n",
       "  'parents': 'ice-skater.n.01',\n",
       "  'case': 'predict_hypernym'},\n",
       " {'children': 'laminectomy.n.01',\n",
       "  'grandparents': None,\n",
       "  'parents': 'ablation.n.01',\n",
       "  'case': 'predict_hypernym'}]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'children': 'dancing.n.01',\n",
       "  'parents': 'diversion.n.01',\n",
       "  'grandparents': None,\n",
       "  'case': 'predict_hypernym'},\n",
       " {'children': 'bagel.n.01',\n",
       "  'parents': 'bun.n.01',\n",
       "  'grandparents': None,\n",
       "  'case': 'predict_hypernym'},\n",
       " {'children': 'shopping_bag.n.01',\n",
       "  'parents': 'bag.n.01',\n",
       "  'grandparents': None,\n",
       "  'case': 'predict_hypernym'},\n",
       " {'children': 'pteridology.n.01',\n",
       "  'parents': 'botany.n.02',\n",
       "  'grandparents': None,\n",
       "  'case': 'predict_hypernym'},\n",
       " {'children': 'house_wren.n.01',\n",
       "  'parents': 'wren.n.02',\n",
       "  'grandparents': None,\n",
       "  'case': 'predict_hypernym'}]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/noun/test_hypernyms.pickle', 'wb') as f:\n",
    "    pickle.dump(test, f)\n",
    "\n",
    "with open('../data/noun/train_hypernyms.pickle', 'wb') as f:\n",
    "    pickle.dump(train, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
