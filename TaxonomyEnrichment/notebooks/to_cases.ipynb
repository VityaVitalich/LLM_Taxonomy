{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import glob\n",
    "import networkx as nx\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "sys.path.append('../../')\n",
    "from DataConstructor.notebooks.leafer import Leafer\n",
    "\n",
    "\n",
    "\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.read_edgelist(\"../../TaxonomyEnrichment/data/verb/train.edgelist\", delimiter=\"\\t\", create_using=nx.DiGraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "wn = True\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        cycle = nx.find_cycle(G)\n",
    "        print(cycle)\n",
    "        G.remove_edge(*cycle[0])\n",
    "    except:\n",
    "        break\n",
    "\n",
    "if not wn:\n",
    "    new_labels = {}\n",
    "    for node in G.nodes():\n",
    "        new_labels[node] = node + '.n.1'\n",
    "\n",
    "    G_new = nx.relabel_nodes(G, new_labels)\n",
    "\n",
    "    l = Leafer(G_new)\n",
    "else:\n",
    "    l = Leafer(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11682"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(G.edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_hypernym 7822 7822\n"
     ]
    }
   ],
   "source": [
    "train, test = l.split_train_test(\n",
    "    generation_depth=0,  # до какого уровня в топ. сортировке идти\n",
    "    p=0.0,  # вероятность что подходящий случай уйдет в тест\n",
    "    p_divide_leafs=0.5,\n",
    "    # вероятность что листья поделим пополам трейн-тест\n",
    "    # а не засунем целый случай в трейн или в тест\n",
    "    min_to_test_rate=0.5,\n",
    "    # минимальное количество доли вершин которых не было в\n",
    "    # трейне чтобы поделить пополам на трейн-тест\n",
    "    # то есть если 6\\10 вершин были трейне то значит все 10 в трейн\n",
    "    # если 5\\10 были в трейне, то значит оставшиеся можем кинуть в тест\n",
    "    weights=[0.00, 0.0, 0.0, 0.00, 0.00, 1.],\n",
    "    # веса в соответствии\n",
    "    # один ребенок, только листья, не только листья\n",
    "    # триплеты с 2 родителями, триплеты такие что мидл нода имеет\n",
    "    # 1 ребенка, предсказание родителя\n",
    "    #p_parent=1\n",
    "    use_1sense_hypernyms=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = '../data/verb/test_nodes.pickle'\n",
    "with open(test_path, 'rb') as f:\n",
    "    test_nodes = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([('hit.v.15', ['consume.v.02']),\n",
       "  ('submit.v.06', ['yield.v.13']),\n",
       "  ('shaft.v.01', ['equip.v.01']),\n",
       "  ('concuss.v.01', ['shake.v.01']),\n",
       "  ('raise.v.21', ['incite.v.02'])],\n",
       " [{'children': 'lock_out.v.01',\n",
       "   'parents': 'exclude.v.02',\n",
       "   'grandparents': None,\n",
       "   'case': 'predict_hypernym'},\n",
       "  {'children': 'caddie.v.01',\n",
       "   'parents': 'serve.v.02',\n",
       "   'grandparents': None,\n",
       "   'case': 'predict_hypernym'},\n",
       "  {'children': 'fort.v.01',\n",
       "   'parents': 'meet.v.07',\n",
       "   'grandparents': None,\n",
       "   'case': 'predict_hypernym'},\n",
       "  {'children': 'overshadow.v.03',\n",
       "   'parents': 'obscure.v.01',\n",
       "   'grandparents': None,\n",
       "   'case': 'predict_hypernym'},\n",
       "  {'children': 'chariot.v.01',\n",
       "   'parents': 'transport.v.02',\n",
       "   'grandparents': None,\n",
       "   'case': 'predict_hypernym'}])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_nodes[:5], train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = []\n",
    "\n",
    "for child, parents in test_nodes:\n",
    "    elem = {}\n",
    "    elem[\"children\"] = child\n",
    "    elem[\"grandparents\"] = None\n",
    "    if len(parents) == 1:\n",
    "        elem[\"parents\"] = parents[0]\n",
    "        elem[\"case\"] = \"predict_hypernym\"\n",
    "    else:\n",
    "        elem[\"parents\"] = parents\n",
    "        elem[\"case\"] = \"predict_multiple_hypernyms\"\n",
    "\n",
    "    test.append(elem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'children': 'hit.v.15',\n",
       "  'grandparents': None,\n",
       "  'parents': 'consume.v.02',\n",
       "  'case': 'predict_hypernym'},\n",
       " {'children': 'submit.v.06',\n",
       "  'grandparents': None,\n",
       "  'parents': 'yield.v.13',\n",
       "  'case': 'predict_hypernym'},\n",
       " {'children': 'shaft.v.01',\n",
       "  'grandparents': None,\n",
       "  'parents': 'equip.v.01',\n",
       "  'case': 'predict_hypernym'},\n",
       " {'children': 'concuss.v.01',\n",
       "  'grandparents': None,\n",
       "  'parents': 'shake.v.01',\n",
       "  'case': 'predict_hypernym'},\n",
       " {'children': 'raise.v.21',\n",
       "  'grandparents': None,\n",
       "  'parents': 'incite.v.02',\n",
       "  'case': 'predict_hypernym'}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'children': 'lock_out.v.01',\n",
       "  'parents': 'exclude.v.02',\n",
       "  'grandparents': None,\n",
       "  'case': 'predict_hypernym'},\n",
       " {'children': 'caddie.v.01',\n",
       "  'parents': 'serve.v.02',\n",
       "  'grandparents': None,\n",
       "  'case': 'predict_hypernym'},\n",
       " {'children': 'fort.v.01',\n",
       "  'parents': 'meet.v.07',\n",
       "  'grandparents': None,\n",
       "  'case': 'predict_hypernym'},\n",
       " {'children': 'overshadow.v.03',\n",
       "  'parents': 'obscure.v.01',\n",
       "  'grandparents': None,\n",
       "  'case': 'predict_hypernym'},\n",
       " {'children': 'chariot.v.01',\n",
       "  'parents': 'transport.v.02',\n",
       "  'grandparents': None,\n",
       "  'case': 'predict_hypernym'}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/verb/test_hypernyms.pickle', 'wb') as f:\n",
    "    pickle.dump(test, f)\n",
    "\n",
    "with open('../data/verb/train_hypernyms_multisense.pickle', 'wb') as f:\n",
    "    pickle.dump(train, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
