{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import scipy\n",
    "import numpy as np\n",
    "from sklearn import preprocessing, svm\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MaxAbsScaler, MinMaxScaler, RobustScaler, normalize\n",
    "from tqdm import tqdm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred = []\n",
    "train_true = []\n",
    "\n",
    "dev_pred = []\n",
    "dev_true = []\n",
    "\n",
    "test_pred = []\n",
    "test_true = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Читаем данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/hyperlex_pairs_ppl.pickle', 'rb') as f:\n",
    "    t = pickle.load(f)\n",
    "\n",
    "# сделаем словарь {пара:перплексия}\n",
    "ppl_dict = dict()\n",
    "for elements in t.items():\n",
    "    v1 = elements[0][0].split('(')[0].strip(' ')\n",
    "    v2 = elements[0][1].strip(',')\n",
    "    ppl = elements[1]\n",
    "    ppl_dict[(v1, v2)] = ppl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lost_train = 0\n",
    "with open('../data/hyperlex/splits/lexical/hyperlex_training_all_lexical.txt', 'r', encoding='utf-8') as f:\n",
    "    for line in f.readlines()[1:]:\n",
    "        splitted = line.split(' ')\n",
    "        v1 = splitted[0]\n",
    "        v2 = splitted[1]\n",
    "        score_10 = splitted[5]\n",
    "        if (v1, v2) in ppl_dict.keys():\n",
    "            train_pred.append(ppl_dict[(v1, v2)])\n",
    "            train_true.append(float(score_10))\n",
    "        else:\n",
    "            lost_train += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lost_dev = 0\n",
    "with open('../data/hyperlex/splits/lexical/hyperlex_dev_all_lexical.txt', 'r', encoding='utf-8') as f:\n",
    "    for line in f.readlines()[1:]:\n",
    "        splitted = line.split(' ')\n",
    "        v1 = splitted[0]\n",
    "        v2 = splitted[1]\n",
    "        score_10 = splitted[5]\n",
    "        if (v1, v2) in ppl_dict.keys():\n",
    "            dev_pred.append(ppl_dict[(v1, v2)])\n",
    "            dev_true.append(float(score_10))\n",
    "        else:\n",
    "            lost_dev += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lost_test = 0\n",
    "with open('../data/hyperlex/splits/lexical/hyperlex_test_all_lexical.txt', 'r', encoding='utf-8') as f:\n",
    "    for line in f.readlines()[1:]:\n",
    "        splitted = line.split(' ')\n",
    "        v1 = splitted[0]\n",
    "        v2 = splitted[1]\n",
    "        score_10 = splitted[5]\n",
    "        if (v1, v2) in ppl_dict.keys():\n",
    "            test_pred.append(ppl_dict[(v1, v2)])\n",
    "            test_true.append(float(score_10))\n",
    "        else:\n",
    "            lost_test += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81\n",
      "13\n",
      "18\n"
     ]
    }
   ],
   "source": [
    "print(lost_train)\n",
    "print(lost_dev)\n",
    "print(lost_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_lexical = []\n",
    "with open('../data/hyperlex/splits/lexical/hyperlex_test_all_lexical.txt', 'r', encoding='utf-8') as f:\n",
    "    for line in f.readlines()[1:]:\n",
    "        splitted = line.split(' ')\n",
    "        v1 = splitted[0]\n",
    "        v2 = splitted[1]\n",
    "\n",
    "        test_lexical.append((v1, v2))\n",
    "\n",
    "\n",
    "test_random = []\n",
    "with open('../data/hyperlex/splits/random/hyperlex_test_all_random.txt', 'r', encoding='utf-8') as f:\n",
    "    for line in f.readlines()[1:]:\n",
    "        splitted = line.split(' ')\n",
    "        v1 = splitted[0]\n",
    "        v2 = splitted[1]\n",
    "\n",
    "        test_random.append((v1, v2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len((set(test_lexical) & set(test_random)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(269, 655)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_lexical), len(test_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Тренируем SVM классификатор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# тут можно вставить очистку от выбросов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = {'forward': [], 'backward': [],  'label': [], 'from': [], 'to': []}\n",
    "test_df = {'forward': [], 'backward': [],  'label': []}\n",
    "\n",
    "\n",
    "with open('../data/hyperlex/splits/lexical/hyperlex_training_all_lexical.txt', 'r', encoding='utf-8') as f:\n",
    "    for line in f.readlines()[1:]:\n",
    "        splitted = line.split(' ')\n",
    "        v1 = splitted[0]\n",
    "        v2 = splitted[1]\n",
    "        score_10 = splitted[5]\n",
    "        if (v1, v2) in ppl_dict.keys():\n",
    "            train_df['forward'].append(ppl_dict[(v1, v2)])\n",
    "            train_df['backward'].append(ppl_dict[(v2, v1)])\n",
    "            train_df['label'].append(float(score_10))\n",
    "            train_df['from'].append(v2)\n",
    "            train_df['to'].append(v1)\n",
    "        else:\n",
    "            lost_train += 1\n",
    "\n",
    "with open('../data/hyperlex/splits/lexical/hyperlex_test_all_lexical.txt', 'r', encoding='utf-8') as f:\n",
    "    for line in f.readlines()[1:]:\n",
    "        splitted = line.split(' ')\n",
    "        v1 = splitted[0]\n",
    "        v2 = splitted[1]\n",
    "        score_10 = splitted[5]\n",
    "        if (v1, v2) in ppl_dict.keys():\n",
    "            test_df['forward'].append(ppl_dict[(v1, v2)])\n",
    "            test_df['backward'].append(ppl_dict[(v2, v1)])\n",
    "            test_df['label'].append(float(score_10))\n",
    "        else:\n",
    "            lost_test += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.DataFrame(train_df)\n",
    "test = pd.DataFrame(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>forward</th>\n",
       "      <th>backward</th>\n",
       "      <th>label</th>\n",
       "      <th>from</th>\n",
       "      <th>to</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>5.632378</td>\n",
       "      <td>17.312578</td>\n",
       "      <td>0.55</td>\n",
       "      <td>loser</td>\n",
       "      <td>winner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>1.264195</td>\n",
       "      <td>24.980017</td>\n",
       "      <td>1.03</td>\n",
       "      <td>dollar</td>\n",
       "      <td>cent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>7.609787</td>\n",
       "      <td>1.872348</td>\n",
       "      <td>1.67</td>\n",
       "      <td>eagle</td>\n",
       "      <td>hawk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>1.751765</td>\n",
       "      <td>18.298920</td>\n",
       "      <td>1.22</td>\n",
       "      <td>face</td>\n",
       "      <td>jaw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>8.007448</td>\n",
       "      <td>5.560601</td>\n",
       "      <td>1.32</td>\n",
       "      <td>girlfriend</td>\n",
       "      <td>boyfriend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>6.737236</td>\n",
       "      <td>74.715446</td>\n",
       "      <td>1.67</td>\n",
       "      <td>toilet</td>\n",
       "      <td>stool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>5.435464</td>\n",
       "      <td>13.931234</td>\n",
       "      <td>0.28</td>\n",
       "      <td>aunt</td>\n",
       "      <td>uncle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>3.560813</td>\n",
       "      <td>19.680157</td>\n",
       "      <td>1.90</td>\n",
       "      <td>whistle</td>\n",
       "      <td>hum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>8.647842</td>\n",
       "      <td>27.846411</td>\n",
       "      <td>0.75</td>\n",
       "      <td>innocence</td>\n",
       "      <td>guilt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>8.412739</td>\n",
       "      <td>14.042396</td>\n",
       "      <td>0.75</td>\n",
       "      <td>pearl</td>\n",
       "      <td>diamond</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631</th>\n",
       "      <td>8.096214</td>\n",
       "      <td>32.015713</td>\n",
       "      <td>1.28</td>\n",
       "      <td>green</td>\n",
       "      <td>brown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>731</th>\n",
       "      <td>9.566100</td>\n",
       "      <td>17.592901</td>\n",
       "      <td>1.67</td>\n",
       "      <td>noun</td>\n",
       "      <td>adverb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732</th>\n",
       "      <td>8.364296</td>\n",
       "      <td>40.223888</td>\n",
       "      <td>1.53</td>\n",
       "      <td>buy</td>\n",
       "      <td>sell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754</th>\n",
       "      <td>1.876777</td>\n",
       "      <td>4.420045</td>\n",
       "      <td>0.52</td>\n",
       "      <td>sunrise</td>\n",
       "      <td>sunset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>7.953592</td>\n",
       "      <td>3.150676</td>\n",
       "      <td>1.25</td>\n",
       "      <td>mammal</td>\n",
       "      <td>animal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>6.963005</td>\n",
       "      <td>45.918926</td>\n",
       "      <td>1.67</td>\n",
       "      <td>face</td>\n",
       "      <td>nose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009</th>\n",
       "      <td>7.529109</td>\n",
       "      <td>15.879882</td>\n",
       "      <td>0.90</td>\n",
       "      <td>employer</td>\n",
       "      <td>employee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1019</th>\n",
       "      <td>4.420045</td>\n",
       "      <td>1.876777</td>\n",
       "      <td>0.75</td>\n",
       "      <td>sunset</td>\n",
       "      <td>sunrise</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       forward   backward  label        from         to\n",
       "58    5.632378  17.312578   0.55       loser     winner\n",
       "79    1.264195  24.980017   1.03      dollar       cent\n",
       "114   7.609787   1.872348   1.67       eagle       hawk\n",
       "164   1.751765  18.298920   1.22        face        jaw\n",
       "312   8.007448   5.560601   1.32  girlfriend  boyfriend\n",
       "340   6.737236  74.715446   1.67      toilet      stool\n",
       "469   5.435464  13.931234   0.28        aunt      uncle\n",
       "490   3.560813  19.680157   1.90     whistle        hum\n",
       "502   8.647842  27.846411   0.75   innocence      guilt\n",
       "606   8.412739  14.042396   0.75       pearl    diamond\n",
       "631   8.096214  32.015713   1.28       green      brown\n",
       "731   9.566100  17.592901   1.67        noun     adverb\n",
       "732   8.364296  40.223888   1.53         buy       sell\n",
       "754   1.876777   4.420045   0.52     sunrise     sunset\n",
       "797   7.953592   3.150676   1.25      mammal     animal\n",
       "871   6.963005  45.918926   1.67        face       nose\n",
       "1009  7.529109  15.879882   0.90    employer   employee\n",
       "1019  4.420045   1.876777   0.75      sunset    sunrise"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.loc[(train['forward'] < 10) & (train['label'] < 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>forward</th>\n",
       "      <th>backward</th>\n",
       "      <th>label</th>\n",
       "      <th>from</th>\n",
       "      <th>to</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8008.550293</td>\n",
       "      <td>315.885620</td>\n",
       "      <td>0.00</td>\n",
       "      <td>dinner</td>\n",
       "      <td>rhyme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>17046.480469</td>\n",
       "      <td>2331.895996</td>\n",
       "      <td>6.00</td>\n",
       "      <td>club</td>\n",
       "      <td>bat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>5938.268066</td>\n",
       "      <td>2342.968262</td>\n",
       "      <td>1.33</td>\n",
       "      <td>worker</td>\n",
       "      <td>integrity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>31782.513672</td>\n",
       "      <td>35.428349</td>\n",
       "      <td>1.55</td>\n",
       "      <td>bra</td>\n",
       "      <td>strap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>5283.479004</td>\n",
       "      <td>1171.315918</td>\n",
       "      <td>0.13</td>\n",
       "      <td>landscape</td>\n",
       "      <td>virtue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>10299.700195</td>\n",
       "      <td>228.982880</td>\n",
       "      <td>0.92</td>\n",
       "      <td>intellect</td>\n",
       "      <td>heart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>31502.958984</td>\n",
       "      <td>147.869232</td>\n",
       "      <td>5.83</td>\n",
       "      <td>food</td>\n",
       "      <td>rabbit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>10217.832031</td>\n",
       "      <td>385.007843</td>\n",
       "      <td>1.07</td>\n",
       "      <td>calculus</td>\n",
       "      <td>clerk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>7420.874512</td>\n",
       "      <td>20.883997</td>\n",
       "      <td>0.17</td>\n",
       "      <td>ball</td>\n",
       "      <td>refrigerator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>5746.648438</td>\n",
       "      <td>87.657219</td>\n",
       "      <td>3.47</td>\n",
       "      <td>problem</td>\n",
       "      <td>caffeine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>640</th>\n",
       "      <td>32121.693359</td>\n",
       "      <td>365.891418</td>\n",
       "      <td>0.52</td>\n",
       "      <td>cancer</td>\n",
       "      <td>hammer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>726</th>\n",
       "      <td>38244.605469</td>\n",
       "      <td>811.201782</td>\n",
       "      <td>0.25</td>\n",
       "      <td>meaning</td>\n",
       "      <td>squash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>5278.784668</td>\n",
       "      <td>1781.701172</td>\n",
       "      <td>1.42</td>\n",
       "      <td>car</td>\n",
       "      <td>horn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>849</th>\n",
       "      <td>5676.849609</td>\n",
       "      <td>1607.970459</td>\n",
       "      <td>1.43</td>\n",
       "      <td>darkness</td>\n",
       "      <td>robber</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>928</th>\n",
       "      <td>80986.148438</td>\n",
       "      <td>6510.470703</td>\n",
       "      <td>0.52</td>\n",
       "      <td>fiddle</td>\n",
       "      <td>father</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1029</th>\n",
       "      <td>11604.430664</td>\n",
       "      <td>9788.008789</td>\n",
       "      <td>0.15</td>\n",
       "      <td>ax</td>\n",
       "      <td>sport</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           forward     backward  label       from            to\n",
       "4      8008.550293   315.885620   0.00     dinner         rhyme\n",
       "25    17046.480469  2331.895996   6.00       club           bat\n",
       "64     5938.268066  2342.968262   1.33     worker     integrity\n",
       "86    31782.513672    35.428349   1.55        bra         strap\n",
       "196    5283.479004  1171.315918   0.13  landscape        virtue\n",
       "200   10299.700195   228.982880   0.92  intellect         heart\n",
       "228   31502.958984   147.869232   5.83       food        rabbit\n",
       "239   10217.832031   385.007843   1.07   calculus         clerk\n",
       "261    7420.874512    20.883997   0.17       ball  refrigerator\n",
       "412    5746.648438    87.657219   3.47    problem      caffeine\n",
       "640   32121.693359   365.891418   0.52     cancer        hammer\n",
       "726   38244.605469   811.201782   0.25    meaning        squash\n",
       "744    5278.784668  1781.701172   1.42        car          horn\n",
       "849    5676.849609  1607.970459   1.43   darkness        robber\n",
       "928   80986.148438  6510.470703   0.52     fiddle        father\n",
       "1029  11604.430664  9788.008789   0.15         ax         sport"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.loc[(train['forward'] > 5000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_test = deepcopy(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>forward</th>\n",
       "      <th>backward</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26.051916</td>\n",
       "      <td>38.237873</td>\n",
       "      <td>6.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4501.588867</td>\n",
       "      <td>701.239014</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14.122448</td>\n",
       "      <td>7.949615</td>\n",
       "      <td>7.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>296.038849</td>\n",
       "      <td>1.950968</td>\n",
       "      <td>2.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29.477560</td>\n",
       "      <td>10.066352</td>\n",
       "      <td>8.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>34.040295</td>\n",
       "      <td>4.281762</td>\n",
       "      <td>2.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>1.370043</td>\n",
       "      <td>4.104309</td>\n",
       "      <td>7.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>1.098539</td>\n",
       "      <td>4.830306</td>\n",
       "      <td>7.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>2.188994</td>\n",
       "      <td>25.749052</td>\n",
       "      <td>8.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>45.132206</td>\n",
       "      <td>37.295582</td>\n",
       "      <td>2.43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>251 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         forward    backward  label\n",
       "0      26.051916   38.237873   6.15\n",
       "1    4501.588867  701.239014   0.13\n",
       "2      14.122448    7.949615   7.95\n",
       "3     296.038849    1.950968   2.73\n",
       "4      29.477560   10.066352   8.72\n",
       "..           ...         ...    ...\n",
       "246    34.040295    4.281762   2.18\n",
       "247     1.370043    4.104309   7.60\n",
       "248     1.098539    4.830306   7.95\n",
       "249     2.188994   25.749052   8.62\n",
       "250    45.132206   37.295582   2.43\n",
       "\n",
       "[251 rows x 3 columns]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['diff'] = train['backward'] - train['forward']\n",
    "train['frac'] = train['forward'] / train['backward']\n",
    "\n",
    "test['diff'] = test['backward'] - test['forward']\n",
    "test['frac'] = test['forward'] / test['backward']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>forward</th>\n",
       "      <th>backward</th>\n",
       "      <th>label</th>\n",
       "      <th>diff</th>\n",
       "      <th>frac</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.931981</td>\n",
       "      <td>4.968969</td>\n",
       "      <td>1.18</td>\n",
       "      <td>-0.963012</td>\n",
       "      <td>1.193805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30.488420</td>\n",
       "      <td>20.915428</td>\n",
       "      <td>1.37</td>\n",
       "      <td>-9.572992</td>\n",
       "      <td>1.457700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5468.501953</td>\n",
       "      <td>204.522263</td>\n",
       "      <td>0.83</td>\n",
       "      <td>-5263.979691</td>\n",
       "      <td>26.737930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>308.169037</td>\n",
       "      <td>298.860352</td>\n",
       "      <td>1.80</td>\n",
       "      <td>-9.308685</td>\n",
       "      <td>1.031147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.300138</td>\n",
       "      <td>383.533386</td>\n",
       "      <td>6.83</td>\n",
       "      <td>382.233248</td>\n",
       "      <td>0.003390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1688</th>\n",
       "      <td>30.611895</td>\n",
       "      <td>197.957733</td>\n",
       "      <td>0.55</td>\n",
       "      <td>167.345839</td>\n",
       "      <td>0.154639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1689</th>\n",
       "      <td>940.610779</td>\n",
       "      <td>34.310448</td>\n",
       "      <td>0.90</td>\n",
       "      <td>-906.300331</td>\n",
       "      <td>27.414704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1690</th>\n",
       "      <td>97.229393</td>\n",
       "      <td>208.553116</td>\n",
       "      <td>0.38</td>\n",
       "      <td>111.323723</td>\n",
       "      <td>0.466209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1691</th>\n",
       "      <td>20.774494</td>\n",
       "      <td>21.602917</td>\n",
       "      <td>5.92</td>\n",
       "      <td>0.828423</td>\n",
       "      <td>0.961652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1692</th>\n",
       "      <td>83.633614</td>\n",
       "      <td>1131.610229</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1047.976616</td>\n",
       "      <td>0.073907</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1693 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          forward     backward  label         diff       frac\n",
       "0        5.931981     4.968969   1.18    -0.963012   1.193805\n",
       "1       30.488420    20.915428   1.37    -9.572992   1.457700\n",
       "2     5468.501953   204.522263   0.83 -5263.979691  26.737930\n",
       "3      308.169037   298.860352   1.80    -9.308685   1.031147\n",
       "4        1.300138   383.533386   6.83   382.233248   0.003390\n",
       "...           ...          ...    ...          ...        ...\n",
       "1688    30.611895   197.957733   0.55   167.345839   0.154639\n",
       "1689   940.610779    34.310448   0.90  -906.300331  27.414704\n",
       "1690    97.229393   208.553116   0.38   111.323723   0.466209\n",
       "1691    20.774494    21.602917   5.92     0.828423   0.961652\n",
       "1692    83.633614  1131.610229   0.60  1047.976616   0.073907\n",
       "\n",
       "[1693 rows x 5 columns]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, Normalizer\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import make_scorer\n",
    "from scipy.stats import spearmanr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "# Custom scorer function for Spearman correlation\n",
    "def spearman_scorer(y_true, y_pred):\n",
    "    return spearmanr(y_true, y_pred)[0]\n",
    "\n",
    "\n",
    "class ColumnDropper(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns_to_drop=None):\n",
    "        self.columns_to_drop = columns_to_drop\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        if self.columns_to_drop is not None:\n",
    "            print(X.drop(columns=self.columns_to_drop))\n",
    "            return X.drop(columns=self.columns_to_drop)\n",
    "        return X\n",
    "\n",
    "# Assuming df_train and df_test are your DataFrame variables for training and testing\n",
    "# Splitting the DataFrame into features (X) and target (y)\n",
    "X_train = train.drop(columns=['label'])\n",
    "y_train = train['label']\n",
    "X_test = test.drop(columns=['label'])\n",
    "y_test = test['label']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [01:25<00:00, 12.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'C': 0, 'epsilon': 0.01, 'kernel': 'linear'}\n",
      "Best Spearman correlation on test set: 0.6126019164163569\n",
      "Best model: SVR()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "columns_to_drop = [['forward'], ['backward'], ['diff'], ['frac'], ['forward', 'backward'], ['diff', 'frac'], ['backward', 'diff', 'frac']]\n",
    "normalizers = [StandardScaler(), MinMaxScaler(), Normalizer(), None]\n",
    "models = [#{'model': Ridge(), 'alpha': [0.1, 0.5, 1, 10, 15]},\n",
    "       #  {'model': DecisionTreeRegressor(), 'max_depth': [None, 1, 2, 3, 4 ,5, 10, 20, 30]},\n",
    "        {'model': svm.SVR(), 'C': [0], 'epsilon': [0.01, 0.1,], 'kernel': ['linear', 'poly', 'rbf', 'sigmoid']},\n",
    "     #   {'model': RandomForestRegressor(), 'n_estimators': [100], 'max_depth': [ 2, 3, 4], 'min_samples_split': [2, 5, 7]}\n",
    "\n",
    "]\n",
    "\n",
    "best_score = -np.inf  # Initialize with a very low score\n",
    "best_params = None\n",
    "best_model = None\n",
    "best_drop = None\n",
    "\n",
    "\n",
    "for col_drop in tqdm(columns_to_drop):\n",
    "    for norm in normalizers:\n",
    "        X_train = train.drop(columns=['label'])\n",
    "        X_train = X_train.drop(columns=col_drop)\n",
    "        X_test = test.drop(columns=['label'])\n",
    "        X_test = X_test.drop(columns=col_drop)\n",
    "\n",
    "        if norm:\n",
    "            if str(norm) == 'Normalizer()':\n",
    "                for column in X_train.columns:\n",
    "                    X_train[column] = norm.transform(X_train[column].values.reshape(1, -1))[0]\n",
    "                    X_test[column] = norm.transform(X_test[column].values.reshape(1, -1))[0]\n",
    "            else:\n",
    "                X_train = norm.fit_transform(X_train)\n",
    "                X_test = norm.transform(X_test)\n",
    "\n",
    "        for params in (models):\n",
    "            \n",
    "            product_combinations = []\n",
    "            naming = []\n",
    "            for k, v in params.items():\n",
    "                if k == 'model':\n",
    "                    continue\n",
    "                \n",
    "                product_combinations.append(v)\n",
    "                naming.append(k)\n",
    "\n",
    "            all_possible = itertools.product(*product_combinations)\n",
    "\n",
    "            \n",
    "            for option in (all_possible):\n",
    "                cur_params = {}\n",
    "                for i, n in enumerate(naming):\n",
    "                    cur_params[n] = option[i]\n",
    "\n",
    "                    model = params['model']\n",
    "            # Fit the model on the training data\n",
    "                    model.fit(X_train, y_train)\n",
    "\n",
    "            # Predict on the test set\n",
    "                    y_pred = model.predict(X_test)\n",
    "            \n",
    "            # Calculate Spearman correlation for the current model\n",
    "                    current_score = spearman_scorer(y_test, y_pred)\n",
    "                    \n",
    "                    # Update the best score, params, and model if current model is better\n",
    "                    if current_score > best_score:\n",
    "                        best_drop = col_drop\n",
    "                        best_score = current_score\n",
    "                        best_params = cur_params\n",
    "                        best_model = model\n",
    "\n",
    "print(f\"Best parameters: {best_params}\")\n",
    "print(f\"Best Spearman correlation on test set: {best_score}\")\n",
    "print(f\"Best model: {model}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['backward']"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.31078838e-03, 5.22907069e-01, 1.08218358e-04],\n",
       "       [9.57059858e-05, 5.22232689e-01, 3.14719142e-03],\n",
       "       [9.67586520e-04, 5.22792798e-01, 2.54342250e-05],\n",
       "       ...,\n",
       "       [1.20321495e-03, 5.22889702e-01, 5.22887408e-05],\n",
       "       [9.67118031e-05, 5.21706101e-01, 1.40503186e-02],\n",
       "       [2.36455344e-02, 5.33560407e-01, 1.77541027e-05]])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#rf {'n_estimators': 50, 'max_depth': 3, 'min_samples_split': 5} 0.7165725548766279\n",
    "# 0.7212313939520568"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;preprocess&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;scaler&#x27;, &#x27;passthrough&#x27;,\n",
       "                                                  [&#x27;forward&#x27;, &#x27;backward&#x27;,\n",
       "                                                   &#x27;diff&#x27;, &#x27;frac&#x27;])])),\n",
       "                (&#x27;model&#x27;, SVR(epsilon=0.2))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocess&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;scaler&#x27;, &#x27;passthrough&#x27;,\n",
       "                                                  [&#x27;forward&#x27;, &#x27;backward&#x27;,\n",
       "                                                   &#x27;diff&#x27;, &#x27;frac&#x27;])])),\n",
       "                (&#x27;model&#x27;, SVR(epsilon=0.2))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocess: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;scaler&#x27;, &#x27;passthrough&#x27;,\n",
       "                                 [&#x27;forward&#x27;, &#x27;backward&#x27;, &#x27;diff&#x27;, &#x27;frac&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">scaler</label><div class=\"sk-toggleable__content\"><pre>[&#x27;forward&#x27;, &#x27;backward&#x27;, &#x27;diff&#x27;, &#x27;frac&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">passthrough</label><div class=\"sk-toggleable__content\"><pre>passthrough</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVR</label><div class=\"sk-toggleable__content\"><pre>SVR(epsilon=0.2)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('preprocess',\n",
       "                 ColumnTransformer(transformers=[('scaler', 'passthrough',\n",
       "                                                  ['forward', 'backward',\n",
       "                                                   'diff', 'frac'])])),\n",
       "                ('model', SVR(epsilon=0.2))])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples, n_features = len(train_pred), 1\n",
    "y = np.array(train_true)\n",
    "X = np.array(train_pred).reshape(-1, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 8.87553501],\n",
       "        [21.44285583],\n",
       "        [ 1.5591203 ],\n",
       "        ...,\n",
       "        [ 3.95151901],\n",
       "        [96.59487152],\n",
       "        [26.34075165]]),\n",
       " array([7.5 , 0.15, 9.77, ..., 2.37, 3.  , 9.55]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = make_pipeline(StandardScaler(), svm.SVR(C=1.0, epsilon=0.2))\n",
    "regr.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11643634884762444"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr.score(np.array(test_pred).reshape(-1, 1), np.array(test_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson:  PearsonRResult(statistic=0.5215759959640544, pvalue=6.513973719853692e-19)\n",
      "Spearman:  SignificanceResult(statistic=0.7058573767815767, pvalue=3.6753305791994724e-39)\n"
     ]
    }
   ],
   "source": [
    "svm_test_pred = regr.predict(np.array(test_pred).reshape(-1, 1))\n",
    "print('Pearson: ', scipy.stats.pearsonr(svm_test_pred, test_true))\n",
    "print('Spearman: ', scipy.stats.spearmanr(svm_test_pred, test_true))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь будем экспериментировать с параметрами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:00,  5.25it/s]\n",
      "4it [00:00, 10.37it/s]\n",
      "4it [00:00, 20.91it/s]\n"
     ]
    }
   ],
   "source": [
    "kernels = ['linear', 'rbf', 'sigmoid'] # 'poly', 'precomputed'\n",
    "scalers = [StandardScaler(), MaxAbsScaler(), MinMaxScaler(), RobustScaler()]\n",
    "\n",
    "with open('svm_lexical_split_experiments.csv', 'w', encoding='utf-8') as f:\n",
    "    f.write('kernel,scaler,pearson,spearman\\n')\n",
    "    for kernel in kernels:\n",
    "        for si, scaler in tqdm(enumerate(scalers)):\n",
    "            y = np.array(train_true)\n",
    "            X = np.array(train_pred).reshape(-1, 1)\n",
    "            regr = make_pipeline(scaler, svm.SVR(C=1.0, epsilon=0.2, kernel=kernel))\n",
    "            regr.fit(X, y)\n",
    "            svm_test_pred = regr.predict(np.array(test_pred).reshape(-1, 1))\n",
    "            pearson = scipy.stats.pearsonr(svm_test_pred, test_true)\n",
    "            spearman = scipy.stats.spearmanr(svm_test_pred, test_true)\n",
    "            f.write(kernel+','+str(si)+','+str(pearson[0])+','+str(spearman[0])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>forward</th>\n",
       "      <th>backward</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26.051916</td>\n",
       "      <td>38.237873</td>\n",
       "      <td>6.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4501.588867</td>\n",
       "      <td>701.239014</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14.122448</td>\n",
       "      <td>7.949615</td>\n",
       "      <td>7.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>296.038849</td>\n",
       "      <td>1.950968</td>\n",
       "      <td>2.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29.477560</td>\n",
       "      <td>10.066352</td>\n",
       "      <td>8.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>34.040295</td>\n",
       "      <td>4.281762</td>\n",
       "      <td>2.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>1.370043</td>\n",
       "      <td>4.104309</td>\n",
       "      <td>7.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>1.098539</td>\n",
       "      <td>4.830306</td>\n",
       "      <td>7.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>2.188994</td>\n",
       "      <td>25.749052</td>\n",
       "      <td>8.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>45.132206</td>\n",
       "      <td>37.295582</td>\n",
       "      <td>2.43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>251 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         forward    backward  label\n",
       "0      26.051916   38.237873   6.15\n",
       "1    4501.588867  701.239014   0.13\n",
       "2      14.122448    7.949615   7.95\n",
       "3     296.038849    1.950968   2.73\n",
       "4      29.477560   10.066352   8.72\n",
       "..           ...         ...    ...\n",
       "246    34.040295    4.281762   2.18\n",
       "247     1.370043    4.104309   7.60\n",
       "248     1.098539    4.830306   7.95\n",
       "249     2.188994   25.749052   8.62\n",
       "250    45.132206   37.295582   2.43\n",
       "\n",
       "[251 rows x 3 columns]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(test['label'])\n",
    "\n",
    "norm_test_pred = normalize([np.array(test['forward'])], norm='max')[0].reshape(-1, 1).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman:  SignificanceResult(statistic=-0.7058839380077765, pvalue=3.6411575820150636e-39)\n"
     ]
    }
   ],
   "source": [
    "print('Spearman: ', scipy.stats.spearmanr(norm_test_pred, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson:  PearsonRResult(statistic=0.6178086955415456, pvalue=8.225887918634271e-28)\n",
      "Spearman:  SignificanceResult(statistic=0.7016386951688859, pvalue=1.5993761706225828e-38)\n"
     ]
    }
   ],
   "source": [
    "# с нормализацией\n",
    "y = np.array(train_true)\n",
    "X = normalize([np.array(train_pred)])[0].reshape(-1, 1)\n",
    "regr = make_pipeline(StandardScaler(), svm.SVR(C=1.0, epsilon=0.2))\n",
    "regr.fit(X, y)\n",
    "\n",
    "norm_test_pred = normalize([np.array(test_pred)])[0].reshape(-1, 1)\n",
    "svm_test_pred = regr.predict(norm_test_pred)\n",
    "print('Pearson: ', scipy.stats.pearsonr(svm_test_pred, test_true))\n",
    "print('Spearman: ', scipy.stats.spearmanr(svm_test_pred, test_true))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
