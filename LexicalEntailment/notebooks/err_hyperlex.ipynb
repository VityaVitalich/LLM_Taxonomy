{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "import pickle\n",
    "import scipy\n",
    "import numpy as np\n",
    "from sklearn import preprocessing, svm\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MaxAbsScaler, MinMaxScaler, RobustScaler, normalize\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import networkx as nx\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import glob\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/hyperlex_pairs_ppl.pickle', 'rb') as f:\n",
    "    t = pickle.load(f)\n",
    "\n",
    "# сделаем словарь {пара:перплексия}\n",
    "ppl_dict = dict()\n",
    "for elements in t.items():\n",
    "    v1 = elements[0][0].split('(')[0].strip(' ')\n",
    "    v2 = elements[0][1].strip(',')\n",
    "    ppl = elements[1]\n",
    "    ppl_dict[(v1, v2)] = ppl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = {'forward': [], 'backward': [],  'label': [], 'from': [], 'to': []}\n",
    "\n",
    "\n",
    "with open('/home/LLM_Taxonomy/LexicalEntailment/data/hyperlex/hyperlex-all.txt', 'r', encoding='utf-8') as f:\n",
    "    for line in f.readlines()[1:]:\n",
    "        splitted = line.split(' ')\n",
    "        v1 = splitted[0]\n",
    "        v2 = splitted[1]\n",
    "        score_10 = splitted[5]\n",
    "        if (v1, v2) in ppl_dict.keys():\n",
    "            train_df['forward'].append(ppl_dict[(v1, v2)])\n",
    "            train_df['backward'].append(ppl_dict[(v2, v1)])\n",
    "            train_df['label'].append(float(score_10))\n",
    "            train_df['from'].append(v2)\n",
    "            train_df['to'].append(v1)\n",
    "        else:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>forward</th>\n",
       "      <th>backward</th>\n",
       "      <th>label</th>\n",
       "      <th>from</th>\n",
       "      <th>to</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.421397</td>\n",
       "      <td>5.009867</td>\n",
       "      <td>8.67</td>\n",
       "      <td>disagreement</td>\n",
       "      <td>conflict</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.875535</td>\n",
       "      <td>91.182434</td>\n",
       "      <td>7.50</td>\n",
       "      <td>worker</td>\n",
       "      <td>mason</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.051916</td>\n",
       "      <td>38.237873</td>\n",
       "      <td>6.15</td>\n",
       "      <td>light</td>\n",
       "      <td>aura</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21.442856</td>\n",
       "      <td>7.594214</td>\n",
       "      <td>0.15</td>\n",
       "      <td>carrot</td>\n",
       "      <td>radish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4501.588867</td>\n",
       "      <td>701.239014</td>\n",
       "      <td>0.13</td>\n",
       "      <td>duty</td>\n",
       "      <td>tusk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2415</th>\n",
       "      <td>96.594872</td>\n",
       "      <td>7.663406</td>\n",
       "      <td>3.00</td>\n",
       "      <td>climber</td>\n",
       "      <td>person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2416</th>\n",
       "      <td>11.773605</td>\n",
       "      <td>634.021667</td>\n",
       "      <td>6.80</td>\n",
       "      <td>medium</td>\n",
       "      <td>newspaper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2417</th>\n",
       "      <td>26.340752</td>\n",
       "      <td>1627.639282</td>\n",
       "      <td>9.55</td>\n",
       "      <td>event</td>\n",
       "      <td>concert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2418</th>\n",
       "      <td>19189.283203</td>\n",
       "      <td>14.231255</td>\n",
       "      <td>1.53</td>\n",
       "      <td>pie</td>\n",
       "      <td>food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2419</th>\n",
       "      <td>3.337863</td>\n",
       "      <td>5.264764</td>\n",
       "      <td>8.05</td>\n",
       "      <td>road</td>\n",
       "      <td>avenue</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2420 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           forward     backward  label          from         to\n",
       "0         2.421397     5.009867   8.67  disagreement   conflict\n",
       "1         8.875535    91.182434   7.50        worker      mason\n",
       "2        26.051916    38.237873   6.15         light       aura\n",
       "3        21.442856     7.594214   0.15        carrot     radish\n",
       "4      4501.588867   701.239014   0.13          duty       tusk\n",
       "...            ...          ...    ...           ...        ...\n",
       "2415     96.594872     7.663406   3.00       climber     person\n",
       "2416     11.773605   634.021667   6.80        medium  newspaper\n",
       "2417     26.340752  1627.639282   9.55         event    concert\n",
       "2418  19189.283203    14.231255   1.53           pie       food\n",
       "2419      3.337863     5.264764   8.05          road     avenue\n",
       "\n",
       "[2420 rows x 5 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_verteces = np.hstack([df['from'].values, df['to'].values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['disagreement', 'worker', 'light', ..., 'concert', 'food',\n",
       "       'avenue'], dtype=object)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_verteces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4840, 2141)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_verteces), len(set(all_verteces))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.DiGraph()\n",
    "for synset in (wn.all_synsets('n')):\n",
    "    name = synset.name()\n",
    "    G.add_node(name)\n",
    "    hyponyms = synset.hyponyms()\n",
    "\n",
    "    for hypo in hyponyms:\n",
    "        new_name = hypo.name()\n",
    "        G.add_node(new_name)\n",
    "        G.add_edge(name, new_name)\n",
    "\n",
    "for synset in (wn.all_synsets('v')):\n",
    "    name = synset.name()\n",
    "    G.add_node(name)\n",
    "    hyponyms = synset.hyponyms()\n",
    "\n",
    "    for hypo in hyponyms:\n",
    "        new_name = hypo.name()\n",
    "        G.add_node(new_name)\n",
    "        G.add_edge(name, new_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['disagreement', 'worker', 'light', 'carrot', 'duty'], dtype=object)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_verteces[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_wnet = 0\n",
    "found = []\n",
    "\n",
    "for node in list(set(all_verteces)):\n",
    "    node = node.replace(' ', '_')\n",
    "    for i in range(12):\n",
    "        true_name = f'{node}.n.0{i}'\n",
    "        if true_name in G.nodes():\n",
    "            in_wnet += 1\n",
    "            found.append(node)\n",
    "            break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'decade'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1875"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_wnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "both_found = {}\n",
    "\n",
    "for idx, elem in df.iterrows():\n",
    "    child = elem['from']\n",
    "    parent = elem['to']\n",
    "\n",
    "    #child = lemmatizer.lemmatize(child, pos='v')\n",
    "    child = child.replace(' ', '_')\n",
    "\n",
    "    #parent = lemmatizer.lemmatize(parent, pos='v')\n",
    "    parent = parent.replace(' ', '_')\n",
    "    \n",
    "\n",
    "    children = []\n",
    "    for i in range(10):\n",
    "        true_name = f'{child}.v.0{i}'\n",
    "        if true_name in G.nodes():\n",
    "            children.append(true_name)\n",
    "    \n",
    "    parents = []\n",
    "    for i in range(10):\n",
    "        true_name = f'{parent}.v.0{i}'\n",
    "        if true_name in G.nodes():\n",
    "            parents.append(true_name)\n",
    "\n",
    "    both_found[idx] = (children, parents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_keys = []\n",
    "for k, v in both_found.items():\n",
    "    if (len(v[0]) == 0) or (len(v[1]) == 0):\n",
    "        drop_keys.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in drop_keys:\n",
    "    both_found.pop(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "652"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(both_found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = []\n",
    "for k, v in both_found.items():\n",
    "    children = v[0]\n",
    "    parents = v[1]\n",
    "\n",
    "    min_path = 99999999\n",
    "\n",
    "    for child in children:\n",
    "        for parent in parents:\n",
    "            try:\n",
    "                path = (nx.shortest_path_length(G, parent, child))\n",
    "            except nx.NetworkXNoPath:\n",
    "                path = 99999999\n",
    "            \n",
    "            if path < min_path:\n",
    "                min_path = path\n",
    "    \n",
    "    paths.append(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = np.array(paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "652"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(paths != 99999999).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths[(paths != 99999999)].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
