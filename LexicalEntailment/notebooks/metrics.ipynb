{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "perplexions_path = '../data/ant_pairs_formated_def_ppls.pickle'\n",
    "test_dataset_path = '../data/ant_test.txt'\n",
    "\n",
    "with open(perplexions_path, 'rb') as f: #(ребенок, родитель): перплексия\n",
    "    ppls = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ppls_clean = dict()\n",
    "for item in ppls.items():\n",
    "    ppls_clean[(item[0][0].split('(')[0].strip(', '), item[0][1].strip(', '))] = item[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = []\n",
    "y_true = []\n",
    "non_reversed = []\n",
    "not_found = []\n",
    "data = []\n",
    "\n",
    "with open(test_dataset_path, 'r',encoding='utf-8') as f:\n",
    "    i = 0\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        ex1, ex2, category = line.strip('\\n').split('\\t')\n",
    "        s11, v1, s12 = ex1.split(',')\n",
    "        s21, v2, s22 = ex2.split(',')\n",
    "        # if s11 == s21 and s12 == s22:\n",
    "        v1 = v1.strip(' ')\n",
    "        v2 = v2.strip(' ')\n",
    "        if category == 'directional_entailment': # child, parent\n",
    "            data.append((v1, v2, 1))\n",
    "\n",
    "        elif category == 'directional_non-entailment': # parent, child\n",
    "            data.append((v1, v2, 0))\n",
    "        # else:\n",
    "        #     non_reversed.append((s11, s12, v1, s21, s22, v2, category))\n",
    "\n",
    "y_true = [elem[2] for elem in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('sedated', 'was given to', 1),\n",
       " ('was given to', 'sedated', 0),\n",
       " ('calmed', 'was given to', 1),\n",
       " ('was given to', 'calmed', 0),\n",
       " ('subdued', 'was given to', 1),\n",
       " ('were given to', 'subdued', 0),\n",
       " ('stimulated', 'were given to', 1),\n",
       " ('were given to', 'stimulated', 0),\n",
       " ('energized', 'was given to', 1),\n",
       " ('were given to', 'energized', 0),\n",
       " ('enlivened', 'was given to', 1),\n",
       " ('were given to', 'enlivened', 0),\n",
       " ('livened up', 'were given to', 1),\n",
       " ('were given to', 'livened up', 0),\n",
       " ('invigorated', 'was given to', 1)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_binary(data, ppls_clean, thr=0):\n",
    "\n",
    "    y_pred = []\n",
    "\n",
    "    for child, parent, label in data:\n",
    "        if not (child, parent) in ppls_clean.keys():\n",
    "            y_pred.append(0)\n",
    "            continue\n",
    "        \n",
    "        forward_ppl = ppls_clean[(child, parent)]\n",
    "        backward_ppl = ppls_clean[(parent, child)]\n",
    "\n",
    "        if (forward_ppl-backward_ppl < thr):\n",
    "            y_pred.append(1)\n",
    "        else:\n",
    "            y_pred.append(0)\n",
    "    \n",
    "    print('ROC AUC score: ', roc_auc_score(y_true, y_pred))\n",
    "    print('Average precision: ', average_precision_score(y_true, y_pred))\n",
    "\n",
    "def count_diff(data, ppls_clean, low_thr=-100000, high_thr=100000):\n",
    "\n",
    "    y_pred = []\n",
    "\n",
    "    for child, parent, label in data:\n",
    "        if not (child, parent) in ppls_clean.keys():\n",
    "            y_pred.append(0)\n",
    "            continue\n",
    "        \n",
    "        forward_ppl = ppls_clean[(child, parent)]\n",
    "        backward_ppl = ppls_clean[(parent, child)]\n",
    "\n",
    "        y_pred.append(np.clip(backward_ppl-forward_ppl, low_thr, high_thr))\n",
    "    y_pred = preprocessing.normalize(np.array([y_pred]), norm='l1')[0]\n",
    "    roc_auc =  roc_auc_score(y_true, y_pred)\n",
    "    ap = average_precision_score(y_true, y_pred)\n",
    "    # print('ROC AUC score: ',)\n",
    "    # print('Average precision: ',)\n",
    "    return roc_auc, ap\n",
    "\n",
    "def count_frac(data, ppls_clean,low_thr=-100000, high_thr=100000):\n",
    "\n",
    "    y_pred = []\n",
    "\n",
    "    for child, parent, label in data:\n",
    "        if not (child, parent) in ppls_clean.keys():\n",
    "            y_pred.append(1)\n",
    "            continue\n",
    "        \n",
    "        forward_ppl = ppls_clean[(child, parent)]\n",
    "        backward_ppl = ppls_clean[(parent, child)]\n",
    "\n",
    "        y_pred.append(np.clip((backward_ppl/forward_ppl), low_thr, high_thr))\n",
    "    y_pred = preprocessing.normalize(np.array([y_pred]), norm='max')[0]\n",
    "    roc_auc =  roc_auc_score(y_true, y_pred)\n",
    "    ap = average_precision_score(y_true, y_pred)\n",
    "    # print('ROC AUC score: ',)\n",
    "    # print('Average precision: ',)\n",
    "    return roc_auc, ap\n",
    "\n",
    "def count_frac_diff(data, ppls_clean):\n",
    "\n",
    "    y_pred_frac = []\n",
    "    y_pred_diff = []\n",
    "\n",
    "    for child, parent, label in data:\n",
    "        if not (child, parent) in ppls_clean.keys():\n",
    "            y_pred_frac.append(1)\n",
    "            y_pred_diff.append(1)\n",
    "            continue\n",
    "        \n",
    "        forward_ppl = ppls_clean[(child, parent)]\n",
    "        backward_ppl = ppls_clean[(parent, child)]\n",
    "\n",
    "        \n",
    "        y_pred_frac.append(backward_ppl/forward_ppl)\n",
    "        y_pred_diff.append(backward_ppl-forward_ppl)\n",
    "    y_pred_frac = preprocessing.normalize(np.array([y_pred_frac]), norm='max')[0]\n",
    "    y_pred_diff = preprocessing.normalize(np.array([y_pred_diff]), norm='max')[0]\n",
    "    y_pred = (y_pred_frac + y_pred_diff) / 2\n",
    "    roc_auc =  roc_auc_score(y_true, y_pred)\n",
    "    ap = average_precision_score(y_true, y_pred)\n",
    "    # print('ROC AUC score: ',)\n",
    "    # print('Average precision: ',)\n",
    "    return roc_auc, ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC score:  0.6310580204778157\n",
      "Average precision:  0.5826467925053981\n"
     ]
    }
   ],
   "source": [
    "count_binary(data, ppls_clean, 1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6313750888187399, 0.6024325798086274)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_diff(data, ppls_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.677718319374716, 0.6549695283131112)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_frac(data, ppls_clean, 0, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6694652238232245, 0.6563200905058708)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_frac_diff(data, ppls_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.contrib.concurrent import process_map\n",
    "import itertools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "lthr = np.arange(-1000, 1000, 20)\n",
    "hthr = np.arange(0, 2000, 20)\n",
    "\n",
    "all_thrs_iterator = itertools.product(lthr, hthr)\n",
    "all_thrs = []\n",
    "for l, h in all_thrs_iterator:\n",
    "    if l < h:\n",
    "        all_thrs.append((l,h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8725"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_thrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = []\n",
    "\n",
    "for i in range(1, 11):\n",
    "    cur_min = (i - 1) * 10000\n",
    "    cur_max = i * 10000\n",
    "    out.extend((process_map(get_metric, all_thrs, chunksize=1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[90], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m     r, a \u001b[38;5;241m=\u001b[39m count_diff(data, ppls_clean, low_thr\u001b[38;5;241m=\u001b[39ml, high_thr\u001b[38;5;241m=\u001b[39mh)\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m r, a\n\u001b[0;32m----> 6\u001b[0m out \u001b[38;5;241m=\u001b[39m (\u001b[43mprocess_map\u001b[49m\u001b[43m(\u001b[49m\u001b[43mget_metric\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_thrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/tqdm/contrib/concurrent.py:105\u001b[0m, in \u001b[0;36mprocess_map\u001b[0;34m(fn, *iterables, **tqdm_kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m     tqdm_kwargs \u001b[38;5;241m=\u001b[39m tqdm_kwargs\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m    104\u001b[0m     tqdm_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlock_name\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmp_lock\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 105\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_executor_map\u001b[49m\u001b[43m(\u001b[49m\u001b[43mProcessPoolExecutor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43miterables\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtqdm_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/tqdm/contrib/concurrent.py:51\u001b[0m, in \u001b[0;36m_executor_map\u001b[0;34m(PoolExecutor, fn, *iterables, **tqdm_kwargs)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ensure_lock(tqdm_class, lock_name\u001b[38;5;241m=\u001b[39mlock_name) \u001b[38;5;28;01mas\u001b[39;00m lk:\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;66;03m# share lock in case workers are already using `tqdm`\u001b[39;00m\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m PoolExecutor(max_workers\u001b[38;5;241m=\u001b[39mmax_workers, initializer\u001b[38;5;241m=\u001b[39mtqdm_class\u001b[38;5;241m.\u001b[39mset_lock,\n\u001b[1;32m     50\u001b[0m                       initargs\u001b[38;5;241m=\u001b[39m(lk,)) \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[0;32m---> 51\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(tqdm_class(\u001b[43mex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43miterables\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs))\n",
      "File \u001b[0;32m/usr/lib/python3.10/concurrent/futures/process.py:766\u001b[0m, in \u001b[0;36mProcessPoolExecutor.map\u001b[0;34m(self, fn, timeout, chunksize, *iterables)\u001b[0m\n\u001b[1;32m    763\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    764\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchunksize must be >= 1.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 766\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_process_chunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    767\u001b[0m \u001b[43m                      \u001b[49m\u001b[43m_get_chunks\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43miterables\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    768\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    769\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _chain_from_iterable_of_lists(results)\n",
      "File \u001b[0;32m/usr/lib/python3.10/concurrent/futures/_base.py:610\u001b[0m, in \u001b[0;36mExecutor.map\u001b[0;34m(self, fn, timeout, chunksize, *iterables)\u001b[0m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    608\u001b[0m     end_time \u001b[38;5;241m=\u001b[39m timeout \u001b[38;5;241m+\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[0;32m--> 610\u001b[0m fs \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubmit(fn, \u001b[38;5;241m*\u001b[39margs) \u001b[38;5;28;01mfor\u001b[39;00m args \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39miterables)]\n\u001b[1;32m    612\u001b[0m \u001b[38;5;66;03m# Yield must be hidden in closure so that the futures are submitted\u001b[39;00m\n\u001b[1;32m    613\u001b[0m \u001b[38;5;66;03m# before the first iterator value is required.\u001b[39;00m\n\u001b[1;32m    614\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mresult_iterator\u001b[39m():\n",
      "File \u001b[0;32m/usr/lib/python3.10/concurrent/futures/_base.py:610\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    608\u001b[0m     end_time \u001b[38;5;241m=\u001b[39m timeout \u001b[38;5;241m+\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[0;32m--> 610\u001b[0m fs \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubmit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m args \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39miterables)]\n\u001b[1;32m    612\u001b[0m \u001b[38;5;66;03m# Yield must be hidden in closure so that the futures are submitted\u001b[39;00m\n\u001b[1;32m    613\u001b[0m \u001b[38;5;66;03m# before the first iterator value is required.\u001b[39;00m\n\u001b[1;32m    614\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mresult_iterator\u001b[39m():\n",
      "File \u001b[0;32m/usr/lib/python3.10/concurrent/futures/process.py:734\u001b[0m, in \u001b[0;36mProcessPoolExecutor.submit\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    732\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_queue_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    733\u001b[0m \u001b[38;5;66;03m# Wake up queue management thread\u001b[39;00m\n\u001b[0;32m--> 734\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_executor_manager_thread_wakeup\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwakeup\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    736\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_safe_to_dynamically_spawn_children:\n\u001b[1;32m    737\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_adjust_process_count()\n",
      "File \u001b[0;32m/usr/lib/python3.10/concurrent/futures/process.py:79\u001b[0m, in \u001b[0;36m_ThreadWakeup.wakeup\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwakeup\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_closed:\n\u001b[0;32m---> 79\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_writer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py:200\u001b[0m, in \u001b[0;36m_ConnectionBase.send_bytes\u001b[0;34m(self, buf, offset, size)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m offset \u001b[38;5;241m+\u001b[39m size \u001b[38;5;241m>\u001b[39m n:\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbuffer length < offset + size\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 200\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mm\u001b[49m\u001b[43m[\u001b[49m\u001b[43moffset\u001b[49m\u001b[43m:\u001b[49m\u001b[43moffset\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py:411\u001b[0m, in \u001b[0;36mConnection._send_bytes\u001b[0;34m(self, buf)\u001b[0m\n\u001b[1;32m    405\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send(buf)\n\u001b[1;32m    406\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    407\u001b[0m     \u001b[38;5;66;03m# Issue #20540: concatenate before sending, to avoid delays due\u001b[39;00m\n\u001b[1;32m    408\u001b[0m     \u001b[38;5;66;03m# to Nagle's algorithm on a TCP socket.\u001b[39;00m\n\u001b[1;32m    409\u001b[0m     \u001b[38;5;66;03m# Also note we want to avoid sending a 0-length buffer separately,\u001b[39;00m\n\u001b[1;32m    410\u001b[0m     \u001b[38;5;66;03m# to avoid \"broken pipe\" errors if the other end closed the pipe.\u001b[39;00m\n\u001b[0;32m--> 411\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send\u001b[49m\u001b[43m(\u001b[49m\u001b[43mheader\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbuf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py:368\u001b[0m, in \u001b[0;36mConnection._send\u001b[0;34m(self, buf, write)\u001b[0m\n\u001b[1;32m    366\u001b[0m remaining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(buf)\n\u001b[1;32m    367\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 368\u001b[0m     n \u001b[38;5;241m=\u001b[39m \u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    369\u001b[0m     remaining \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m n\n\u001b[1;32m    370\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m remaining \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def get_metric(thrs):\n",
    "    l, r = thrs\n",
    "    r, a = count_diff(data, ppls_clean, low_thr=l, high_thr=h)\n",
    "    return r, a\n",
    "\n",
    "out = (process_map(get_metric, all_thrs, chunksize=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = {'forward':[], 'backward':[], 'target':[]}\n",
    "\n",
    "for child, parent, label in data:\n",
    "    if not (child, parent) in ppls_clean.keys():\n",
    "        #y_pred.append(1)\n",
    "        continue\n",
    "    \n",
    "    \n",
    "    forward_ppl = ppls_clean[(child, parent)]\n",
    "    backward_ppl = ppls_clean[(parent, child)]\n",
    "    df['forward'].append(forward_ppl)\n",
    "    df['backward'].append(backward_ppl)\n",
    "    df['target'].append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['frac'] = X['backward'] / X['forward']\n",
    "X['diff'] = X['backward'] - X['forward']\n",
    "X['mul'] = X['backward'] * X['forward']\n",
    "X['sign'] = X['frac'] < 0.5\n",
    "\n",
    "scaler = preprocessing.Normalizer()\n",
    "X[['forward', 'backward', 'frac', 'diff', 'mul']] = scaler.fit_transform(X[['forward', 'backward', 'frac', 'diff', 'mul']] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6920013421334584, 0.6951447181974137)"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dropping = ['target', 'mul', 'sign', 'backward', 'forward', 'frac']\n",
    "\n",
    "logreg = LogisticRegression(C=0.01, max_iter=1000, fit_intercept=False, solver='newton-cg')\n",
    "logreg.fit(X.drop(columns=dropping), X['target'])\n",
    "\n",
    "probas = logreg.predict_proba(X.drop(columns=dropping))\n",
    "y_pred = probas[:,1]\n",
    "y_true = X['target']\n",
    "\n",
    "roc_auc =  roc_auc_score(y_true, y_pred)\n",
    "ap = average_precision_score(y_true, y_pred)\n",
    "\n",
    "roc_auc, ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.27866373]]), array([0.]))"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.coef_, logreg.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6920013421334584, 0.6951447181974137)"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dropping = ['target', 'mul', 'sign', 'backward', 'forward', 'frac']\n",
    "\n",
    "logreg = SGDClassifier(loss='log_loss', tol=1e-15)\n",
    "logreg.fit(X.drop(columns=dropping), X['target'])\n",
    "\n",
    "probas = logreg.predict_proba(X.drop(columns=dropping))\n",
    "y_pred = probas[:,1]\n",
    "y_true = X['target']\n",
    "\n",
    "roc_auc =  roc_auc_score(y_true, y_pred)\n",
    "ap = average_precision_score(y_true, y_pred)\n",
    "\n",
    "roc_auc, ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.717876254913848, 0.6959064805460624)"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dropping = ['target']\n",
    "\n",
    "logreg = DecisionTreeClassifier(max_depth=5)\n",
    "logreg.fit(X.drop(columns=dropping), X['target'])\n",
    "\n",
    "probas = logreg.predict_proba(X.drop(columns=dropping))\n",
    "y_pred = probas[:,1]\n",
    "y_true = X['target']\n",
    "\n",
    "roc_auc =  roc_auc_score(y_true, y_pred)\n",
    "ap = average_precision_score(y_true, y_pred)\n",
    "\n",
    "roc_auc, ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6556946303223027, 0.655444325087572)"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_true_2 = []\n",
    "y_pred_2 = []\n",
    "\n",
    "with open(test_dataset_path, 'r',encoding='utf-8') as f:\n",
    "    i = 0\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        ex1, ex2, category = line.strip('\\n').split('\\t')\n",
    "        s11, v1, s12 = ex1.split(',')\n",
    "        s21, v2, s22 = ex2.split(',')\n",
    "        if s11 == s21 and s12 == s22:\n",
    "            v1 = v1.strip(' ')\n",
    "            v2 = v2.strip(' ')\n",
    "            if category == 'directional_entailment': # child, parent\n",
    "                if (v1, v2) not in ppls_clean.keys():\n",
    "                    x = 0\n",
    "                else:\n",
    "                    y_pred_2.append(ppls_clean[(v1, v2)]-ppls_clean[(v2, v1)])\n",
    "                    y_true_2.append(0)\n",
    "\n",
    "            elif category == 'directional_non-entailment': # parent, child\n",
    "                if (v1, v2) not in ppls_clean.keys():\n",
    "                    x = 0\n",
    "                else:\n",
    "                    y_pred_2.append(ppls_clean[(v1, v2)]-ppls_clean[(v2, v1)])\n",
    "                    y_true_2.append(1)\n",
    "\n",
    "\n",
    "normalized_y_pred = preprocessing.normalize([np.array(y_pred_2)])\n",
    "print('ROC AUC score: ', roc_auc_score(y_true_2, normalized_y_pred[0]))\n",
    "print('Average precision: ', average_precision_score(y_true_2, normalized_y_pred[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
