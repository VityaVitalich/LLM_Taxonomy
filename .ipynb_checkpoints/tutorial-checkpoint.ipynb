{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ba5ee78-7790-4132-b6d5-da8cf9a93f36",
   "metadata": {},
   "source": [
    "Requirements.txt\n",
    "\n",
    "torch 2.0.0+cu117\n",
    "transformers 4.28.1\n",
    "numpy\n",
    "typing\n",
    "tqdm\n",
    "gc\n",
    "pandas\n",
    "collections\n",
    "sklearn\n",
    "contextlib\n",
    "io\n",
    "IPython\n",
    "os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "427b334d-b792-491f-bb7a-73479b6aa96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch transformers -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55145b97-71be-4d72-a9c2-8935a4c05b73",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Apr 24 00:29:47 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 510.108.03   Driver Version: 510.108.03   CUDA Version: 11.6     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:1B:00.0 Off |                  Off |\n",
      "|  0%   34C    P8    25W / 460W |   4531MiB / 24564MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA GeForce ...  Off  | 00000000:1C:00.0 Off |                  N/A |\n",
      "| 27%   33C    P8    15W / 260W |      8MiB / 11264MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA GeForce ...  Off  | 00000000:1E:00.0 Off |                  N/A |\n",
      "| 27%   33C    P8     9W / 260W |      8MiB / 11264MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  NVIDIA GeForce ...  Off  | 00000000:3F:00.0 Off |                  Off |\n",
      "|  0%   33C    P8    18W / 460W |      8MiB / 24564MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  NVIDIA GeForce ...  Off  | 00000000:40:00.0 Off |                  Off |\n",
      "|  0%   37C    P8    31W / 460W |      8MiB / 24564MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  NVIDIA GeForce ...  Off  | 00000000:5E:00.0 Off |                  Off |\n",
      "|  0%   34C    P8    25W / 460W |      8MiB / 24564MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c49ca14d-cbec-4131-a1c7-b22e97aac112",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06732b8f-5876-4f28-96b9-2ee4051909fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9718e589-60a0-44d5-9a91-ede02bdff15a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device='cuda'\n",
    "    print('GPU')\n",
    "else:\n",
    "    device='cpu'\n",
    "    print('CPU')\n",
    "    \n",
    "    \n",
    "SEED = 0\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15c037be-49a4-43b2-8d53-467bae409e9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0          hyperonym: blackfly | hyponyms:\n",
      "1          hyperonym: Turonian | hyponyms:\n",
      "2        hyperonym: abhorrence | hyponyms:\n",
      "3    hyperonym: tropical storm | hyponyms:\n",
      "4    hyperonym: militarization | hyponyms:\n",
      "Name: term, dtype: object\n",
      "0                           homopterous insect, insect\n",
      "1    technical specification, geologic timescale, p...\n",
      "2                      distaste, hatred, hate, disgust\n",
      "3    atmosphere, windstorm, violent storm, air curr...\n",
      "4                                       social control\n",
      "Name: hypernym, dtype: object\n",
      "0    hyperonym: maliciousness | hyponyms:\n",
      "1          hyperonym: buckler | hyponyms:\n",
      "2        hyperonym: spelunker | hyponyms:\n",
      "3     hyperonym: quo warranto | hyponyms:\n",
      "4     hyperonym: Jeff Francis | hyponyms:\n",
      "Name: term, dtype: object\n",
      "0       malevolence, distaste, hatred, hate, malignity\n",
      "1                                           body armor\n",
      "2                    exploration, adventurer, explorer\n",
      "3    proceedings, legal proceedings, proceeding, du...\n",
      "4               thrower, baseball player, jock, person\n",
      "Name: hypernym, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "path_data_en = \"SemEval2018-Task9/training/data/1A.english.training.data.txt\"\n",
    "path_gold_en = \"SemEval2018-Task9/training/gold/1A.english.training.gold.txt\"\n",
    "\n",
    "train_data_en_data = pd.read_csv(path_data_en, header=None, sep=\"\\t\", names=['term', 'relation'])\n",
    "train_gold_en_data = pd.read_csv(path_gold_en, header=None, names=['hypernym'])\n",
    "\n",
    "train_data_en_data.head()\n",
    "\n",
    "path_test_data_en = \"SemEval2018-Task9/test/data/1A.english.test.data.txt\"\n",
    "path_test_gold_en = \"SemEval2018-Task9/test/gold/1A.english.test.gold.txt\"\n",
    "\n",
    "test_data_en_data = pd.read_csv(path_test_data_en, header=None, sep=\"\\t\", names=['term', 'relation'])\n",
    "test_gold_en_data = pd.read_csv(path_test_gold_en, header=None, names=['hypernym'])\n",
    "\n",
    "def standard_preprcessing(train_features, train_target, test_features, test_target):\n",
    "    \n",
    "    train_data_en = train_features.copy()\n",
    "    train_data_en = 'hyperonym: ' + train_data_en.term + ' | hyponyms:'\n",
    "    print(train_data_en.head())\n",
    "\n",
    "    train_gold_en = train_target.copy()\n",
    "    train_gold_en = train_gold_en.hypernym.str.split('\\t').str.join(', ')\n",
    "    print(train_gold_en.head())\n",
    "    \n",
    "    test_data_en = test_features.copy()\n",
    "    test_data_en = 'hyperonym: ' + test_data_en.term + ' | hyponyms:'\n",
    "    print(test_data_en.head())\n",
    "\n",
    "    test_gold_en = test_target.copy()\n",
    "    test_gold_en = test_gold_en.hypernym.str.split('\\t').str.join(', ')\n",
    "    print(test_gold_en.head())\n",
    "    \n",
    "    return train_data_en, train_gold_en, test_data_en, test_gold_en\n",
    "\n",
    "\n",
    "train_data_en, train_gold_en, test_data_en, test_gold_en = standard_preprcessing(train_data_en_data, \n",
    "                                                                                 train_gold_en_data, \n",
    "                                                                                 test_data_en_data, \n",
    "                                                                                 test_gold_en_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a19be5-3df1-418f-a0c3-665bd22637eb",
   "metadata": {},
   "source": [
    "# Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dee3c86a-b668-436f-94b9-071d34acb826",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5ForConditionalGeneration, AutoTokenizer\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, AutoConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6cacd3c0-68be-42f7-8096-ac5581afb449",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44e3d23365e94b1fae96c357a002e366",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad444eafa99d44d89cb92359d98794ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/242M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75eda949a6b342a79b21413ee6dabc9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)neration_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f65dc622510147818fcc971a48321889",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)ve/main/spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b547623f36b94609944b86651e5a03d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/models/t5/tokenization_t5_fast.py:155: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-small automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_checkpoint = \"t5-small\"\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_checkpoint).to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, max_length=100, block_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b9c4baf-fcb8-4178-a31a-8bdcff0fbe41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation.data_collat import DataCollatorWithPadding\n",
    "from evaluation.experiment import Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0809810-2abd-4182-8b77-80e843cda409",
   "metadata": {},
   "source": [
    "1. train params/predict params [1, 1]\n",
    "2. train / params predict [0, 1]\n",
    "3. params predict [0, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7866ee63-7759-4fc2-beae-d345b2d18a9b",
   "metadata": {},
   "source": [
    "## Change only parmeters in generating with no training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21a56839-766a-4911-bd14-b0fb79f71740",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_param = {'GenArgs': {'num_beams': [2, 10]}}\n",
    "\n",
    "freezed_param = {'TrainArgs': {'num_train_epochs':1, 'per_device_train_batch_size':16, 'save_steps':1}, \n",
    "                 'GenArgs': {'max_length': 3, 'early_stopping': True}, \n",
    "                 'SelectStrategy': None, 'PredForm': None}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78419336-4edb-47a8-b261-96661c48fb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "\n",
    "path_data = '/home/jovyan/work/SemEval2018-Task9/test/gold/1A.english.test.gold.txt'\n",
    "\n",
    "experiment1 = Experiment(output_dir='/home/jovyan/work',\n",
    "                         check_param=check_param, freezed_param=freezed_param,\n",
    "                         model=model, tokenizer=tokenizer, device=device,\n",
    "                         data_collator=data_collator,\n",
    "                         data_train=train_data_en.tolist(), target_train=train_gold_en.tolist(), \n",
    "                         data_test=test_data_en.tolist(), target_test=test_gold_en.tolist(), strategy=[0, 0], \n",
    "                         path_to_test=path_data\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "43384857-c13a-4330-8f32-422ca0fe9a54",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1500/1500 [00:42<00:00, 35.07it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1500/1500 [00:46<00:00, 32.09it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MRR</th>\n",
       "      <th>MAP</th>\n",
       "      <th>P@1</th>\n",
       "      <th>P@3</th>\n",
       "      <th>P@5</th>\n",
       "      <th>P@15</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Meta-Params</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>{'GenArgs': {'num_beams': 2}}</th>\n",
       "      <td>0.00133</td>\n",
       "      <td>0.00034</td>\n",
       "      <td>0.00133</td>\n",
       "      <td>0.00044</td>\n",
       "      <td>0.00027</td>\n",
       "      <td>0.0002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'GenArgs': {'num_beams': 10}}</th>\n",
       "      <td>0.00133</td>\n",
       "      <td>0.00034</td>\n",
       "      <td>0.00133</td>\n",
       "      <td>0.00044</td>\n",
       "      <td>0.00027</td>\n",
       "      <td>0.0002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    MRR      MAP      P@1      P@3      P@5  \\\n",
       "Meta-Params                                                                   \n",
       "{'GenArgs': {'num_beams': 2}}   0.00133  0.00034  0.00133  0.00044  0.00027   \n",
       "{'GenArgs': {'num_beams': 10}}  0.00133  0.00034  0.00133  0.00044  0.00027   \n",
       "\n",
       "                                  P@15  \n",
       "Meta-Params                             \n",
       "{'GenArgs': {'num_beams': 2}}   0.0002  \n",
       "{'GenArgs': {'num_beams': 10}}  0.0002  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment1.run_experiment()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd961bff-cd17-437d-97c2-4463c17038b5",
   "metadata": {},
   "source": [
    "## Change only parmeters in generating with training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c28c5062-429e-4965-bc3c-876201e9734c",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_param = {'GenArgs': {'num_beams': [2, 10]}}\n",
    "\n",
    "freezed_param = {'TrainArgs': {'num_train_epochs':1, 'per_device_train_batch_size':16, 'save_steps':1}, \n",
    "                 'GenArgs': {'max_length': 3, 'early_stopping': True}, \n",
    "                 'SelectStrategy': None, 'PredForm': None}\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "\n",
    "path_data = '/home/jovyan/work/SemEval2018-Task9/test/gold/1A.english.test.gold.txt'\n",
    "\n",
    "experiment1 = Experiment(output_dir='/home/jovyan/work',\n",
    "                         check_param=check_param, freezed_param=freezed_param,\n",
    "                         model=model, tokenizer=tokenizer, device=device,\n",
    "                         data_collator=data_collator,\n",
    "                         data_train=train_data_en.tolist(), target_train=train_gold_en.tolist(), \n",
    "                         data_test=test_data_en.tolist(), target_test=test_gold_en.tolist(),\n",
    "                         strategy=[0, 1], \n",
    "                         path_to_test=path_data\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "800bf82a-bc02-461d-97d0-0cd46887356a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='94' max='94' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [94/94 01:44, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 1500/1500 [00:37<00:00, 40.43it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 1500/1500 [00:41<00:00, 36.58it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MRR</th>\n",
       "      <th>MAP</th>\n",
       "      <th>P@1</th>\n",
       "      <th>P@3</th>\n",
       "      <th>P@5</th>\n",
       "      <th>P@15</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Meta-Params</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>{'GenArgs': {'num_beams': 2}}</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'GenArgs': {'num_beams': 10}}</th>\n",
       "      <td>0.00067</td>\n",
       "      <td>0.00019</td>\n",
       "      <td>0.00067</td>\n",
       "      <td>0.00022</td>\n",
       "      <td>0.00013</td>\n",
       "      <td>0.00013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    MRR      MAP      P@1      P@3      P@5  \\\n",
       "Meta-Params                                                                   \n",
       "{'GenArgs': {'num_beams': 2}}       0.0      0.0      0.0      0.0      0.0   \n",
       "{'GenArgs': {'num_beams': 10}}  0.00067  0.00019  0.00067  0.00022  0.00013   \n",
       "\n",
       "                                   P@15  \n",
       "Meta-Params                              \n",
       "{'GenArgs': {'num_beams': 2}}       0.0  \n",
       "{'GenArgs': {'num_beams': 10}}  0.00013  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment1.run_experiment()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b90423c-2dcb-477d-a484-230949f020c8",
   "metadata": {},
   "source": [
    "## Change generating and training parmeters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2f16d5ee-cb5e-43e2-8399-1fd55e1d482e",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_param = {'TrainArgs': {'num_train_epochs':[1, 2]}, 'GenArgs': {'num_beams': [2, 10]}}\n",
    "\n",
    "freezed_param = {'TrainArgs': {'per_device_train_batch_size':16, 'save_steps':1}, \n",
    "                 'GenArgs': {'max_length': 3, 'early_stopping': True}, \n",
    "                 'SelectStrategy': None, 'PredForm': None}\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "\n",
    "path_data = '/home/jovyan/work/SemEval2018-Task9/test/gold/1A.english.test.gold.txt'\n",
    "\n",
    "experiment1 = Experiment(output_dir='/home/jovyan/work',\n",
    "                         check_param=check_param, freezed_param=freezed_param,\n",
    "                         model=model, tokenizer=tokenizer, device=device,\n",
    "                         data_collator=data_collator,\n",
    "                         data_train=train_data_en.tolist(), target_train=train_gold_en.tolist(), \n",
    "                         data_test=test_data_en.tolist(), target_test=test_gold_en.tolist(),\n",
    "                         strategy=[1, 1], \n",
    "                         path_to_test=path_data\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "50e7c844-df40-423a-b0aa-3818c103c939",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='94' max='94' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [94/94 01:42, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 1500/1500 [00:37<00:00, 40.19it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='94' max='94' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [94/94 01:41, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 1500/1500 [00:41<00:00, 36.44it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='188' max='188' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [188/188 03:25, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 1500/1500 [00:37<00:00, 40.52it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='188' max='188' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [188/188 03:24, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 1500/1500 [00:41<00:00, 36.30it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MRR</th>\n",
       "      <th>MAP</th>\n",
       "      <th>P@1</th>\n",
       "      <th>P@3</th>\n",
       "      <th>P@5</th>\n",
       "      <th>P@15</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Meta-Params</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>{'TrainArgs': {'num_train_epochs': 1}, 'GenArgs': {'num_beams': 2}}</th>\n",
       "      <td>0.00133</td>\n",
       "      <td>0.00052</td>\n",
       "      <td>0.00133</td>\n",
       "      <td>0.00044</td>\n",
       "      <td>0.00044</td>\n",
       "      <td>0.00044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'TrainArgs': {'num_train_epochs': 1}, 'GenArgs': {'num_beams': 10}}</th>\n",
       "      <td>0.00467</td>\n",
       "      <td>0.00147</td>\n",
       "      <td>0.00467</td>\n",
       "      <td>0.00156</td>\n",
       "      <td>0.00118</td>\n",
       "      <td>0.00109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'TrainArgs': {'num_train_epochs': 2}, 'GenArgs': {'num_beams': 2}}</th>\n",
       "      <td>0.00533</td>\n",
       "      <td>0.00168</td>\n",
       "      <td>0.00533</td>\n",
       "      <td>0.00178</td>\n",
       "      <td>0.00137</td>\n",
       "      <td>0.00124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'TrainArgs': {'num_train_epochs': 2}, 'GenArgs': {'num_beams': 10}}</th>\n",
       "      <td>0.008</td>\n",
       "      <td>0.00269</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.00278</td>\n",
       "      <td>0.00219</td>\n",
       "      <td>0.00209</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        MRR      MAP      P@1  \\\n",
       "Meta-Params                                                                     \n",
       "{'TrainArgs': {'num_train_epochs': 1}, 'GenArgs...  0.00133  0.00052  0.00133   \n",
       "{'TrainArgs': {'num_train_epochs': 1}, 'GenArgs...  0.00467  0.00147  0.00467   \n",
       "{'TrainArgs': {'num_train_epochs': 2}, 'GenArgs...  0.00533  0.00168  0.00533   \n",
       "{'TrainArgs': {'num_train_epochs': 2}, 'GenArgs...    0.008  0.00269    0.008   \n",
       "\n",
       "                                                        P@3      P@5     P@15  \n",
       "Meta-Params                                                                    \n",
       "{'TrainArgs': {'num_train_epochs': 1}, 'GenArgs...  0.00044  0.00044  0.00044  \n",
       "{'TrainArgs': {'num_train_epochs': 1}, 'GenArgs...  0.00156  0.00118  0.00109  \n",
       "{'TrainArgs': {'num_train_epochs': 2}, 'GenArgs...  0.00178  0.00137  0.00124  \n",
       "{'TrainArgs': {'num_train_epochs': 2}, 'GenArgs...  0.00278  0.00219  0.00209  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment1.run_experiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b8265237-ddf6-46f5-9252-97e4eb281705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Mon Apr 24 00:13:24 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 510.108.03   Driver Version: 510.108.03   CUDA Version: 11.6     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:1B:00.0 Off |                  Off |\n",
      "|  0%   34C    P8    25W / 460W |   4531MiB / 24564MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA GeForce ...  Off  | 00000000:1C:00.0 Off |                  N/A |\n",
      "| 27%   34C    P8    15W / 260W |      8MiB / 11264MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA GeForce ...  Off  | 00000000:1E:00.0 Off |                  N/A |\n",
      "| 27%   34C    P8     8W / 260W |      8MiB / 11264MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  NVIDIA GeForce ...  Off  | 00000000:3F:00.0 Off |                  Off |\n",
      "|  0%   31C    P8    17W / 460W |      8MiB / 24564MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  NVIDIA GeForce ...  Off  | 00000000:40:00.0 Off |                  Off |\n",
      "| 30%   50C    P2   115W / 460W |   2543MiB / 24564MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  NVIDIA GeForce ...  Off  | 00000000:5E:00.0 Off |                  Off |\n",
      "|  0%   35C    P8    25W / 460W |      8MiB / 24564MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "66d4ce72-20cf-438a-9be1-47f77ab48556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!rm -rf experiment"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
