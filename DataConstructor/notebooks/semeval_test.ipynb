{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from leafer import Leafer\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import glob\n",
    "\n",
    "\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "total_test = []\n",
    "\n",
    "subsets = ['1A.english', '2A.medical', '2B.music']\n",
    "for subset in subsets:\n",
    "\n",
    "    data_path = '../../SemEval2018-Task9/test/data/' + subset + '.test.data.txt'\n",
    "    gold_path = '../../SemEval2018-Task9/test/gold/' + subset + '.test.gold.txt'\n",
    "    train_data_en_data = pd.read_csv(\n",
    "                    data_path, header=None, sep=\"\\t\", names=[\"term\", \"relation\"]\n",
    "                )\n",
    "    train_gold_en_data = pd.read_csv(gold_path, header=None, names=[\"hypernym\"])\n",
    "\n",
    "    df = pd.concat([train_data_en_data, train_gold_en_data], axis=1)[\n",
    "        [\"term\", \"hypernym\"]\n",
    "    ]\n",
    "\n",
    "    test = []\n",
    "\n",
    "    for elem in df.iterrows():\n",
    "        idx, row = elem\n",
    "\n",
    "        elem = {}\n",
    "        elem[\"children\"] = row['term']\n",
    "        elem[\"parents\"] = row['hypernym'].split('\\t')\n",
    "        elem[\"grandparents\"] = None\n",
    "        elem[\"case\"] = \"predict_multiple_hypernyms\"\n",
    "\n",
    "        test.append(elem)\n",
    "\n",
    "    total_test += test\n",
    "\n",
    "    test_name = '../../SemEval2018-Task9/custom_datasets/' + subset + '.pickle'\n",
    "\n",
    "    with open(test_name, 'wb') as f:\n",
    "        pickle.dump(test, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_name = '../../SemEval2018-Task9/custom_datasets/test_it.pickle'\n",
    "\n",
    "with open(test_name, 'wb') as f:\n",
    "    pickle.dump(test, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../SemEval2018-Task9/training/data/1A.english.training.data.txt\n",
      "../../SemEval2018-Task9/training/data/2A.medical.training.data.txt\n",
      "../../SemEval2018-Task9/training/data/2B.music.training.data.txt\n"
     ]
    }
   ],
   "source": [
    "# data_path = '../../SemEval2018-Task9/training/data/1A.english.training.data.txt'\n",
    "# gold_path = '../../SemEval2018-Task9/training/gold/1A.english.training.gold.txt'\n",
    "\n",
    "# train_data_en_data = pd.read_csv(\n",
    "#                 data_path, header=None, sep=\"\\t\", names=[\"term\", \"relation\"]\n",
    "#             )\n",
    "# train_gold_en_data = pd.read_csv(gold_path, header=None, names=[\"hypernym\"])\n",
    "\n",
    "# df = pd.concat([train_data_en_data, train_gold_en_data], axis=1)[\n",
    "#     [\"term\", \"hypernym\"]\n",
    "# ]\n",
    "\n",
    "total_train = []\n",
    "\n",
    "subsets = ['1A.english', '2A.medical', '2B.music']\n",
    "for subset in subsets:\n",
    "\n",
    "    data_path = '../../SemEval2018-Task9/training/data/' + subset + '.training.data.txt'\n",
    "    gold_path = '../../SemEval2018-Task9/training/gold/' + subset + '.training.gold.txt'\n",
    "    print(data_path)\n",
    "    train_data_en_data = pd.read_csv(\n",
    "                    data_path, header=None, sep=\"\\t\", names=[\"term\", \"relation\"]\n",
    "                )\n",
    "    train_gold_en_data = pd.read_csv(gold_path, header=None, names=[\"hypernym\"])\n",
    "\n",
    "    df = pd.concat([train_data_en_data, train_gold_en_data], axis=1)[\n",
    "        [\"term\", \"hypernym\"]\n",
    "    ]\n",
    "\n",
    "    train = []\n",
    "\n",
    "    for elem in df.iterrows():\n",
    "        idx, row = elem\n",
    "\n",
    "        elem = {}\n",
    "        elem[\"children\"] = row['term']\n",
    "        elem[\"parents\"] = row['hypernym'].split('\\t')\n",
    "        elem[\"grandparents\"] = None\n",
    "        elem[\"case\"] = \"predict_multiple_hypernyms\"\n",
    "\n",
    "        train.append(elem)\n",
    "\n",
    "    total_train += train\n",
    "\n",
    "    train_name = '../../SemEval2018-Task9/custom_datasets/' + subset + '_train.pickle'\n",
    "\n",
    "    with open(train_name, 'wb') as f:\n",
    "        pickle.dump(train, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/LLM_Taxonomy/SemEval2018-Task9/custom_datasets/2A.medical_train.pickle', 'rb') as f:\n",
    "    train = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('../../pipeline_src/')\n",
    "from dataset.prompt_schemas import predict_multiple_parents_from_child"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "for obj in train:\n",
    "    predict_multiple_parents_from_child(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'children': nan,\n",
       " 'parents': ['function', 'renal function', 'blood flow', 'flow'],\n",
       " 'grandparents': None,\n",
       " 'case': 'predict_multiple_hypernyms'}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = '2A.medical'\n",
    "data_path = '../../SemEval2018-Task9/training/data/' + subset + '.training.data.txt'\n",
    "\n",
    "train_data_en_data = pd.read_csv(\n",
    "                data_path, header=None, sep=\"\\t\", names=[\"term\", \"relation\"]\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>relation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bone spur</td>\n",
       "      <td>Concept</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>endodontics</td>\n",
       "      <td>Concept</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>recurrent cancer</td>\n",
       "      <td>Concept</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>neurohypophyseal diabetes insipidus</td>\n",
       "      <td>Concept</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fixed orthodontic appliance</td>\n",
       "      <td>Concept</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>continuous blood sampling</td>\n",
       "      <td>Concept</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>acute respiratory infection</td>\n",
       "      <td>Concept</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>primary pulmonary lymphoma</td>\n",
       "      <td>Concept</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>psychoactive substance dependence</td>\n",
       "      <td>Concept</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>renal blood flow</td>\n",
       "      <td>Concept</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    term relation\n",
       "0                              bone spur  Concept\n",
       "1                            endodontics  Concept\n",
       "2                       recurrent cancer  Concept\n",
       "3    neurohypophyseal diabetes insipidus  Concept\n",
       "4            fixed orthodontic appliance  Concept\n",
       "..                                   ...      ...\n",
       "495            continuous blood sampling  Concept\n",
       "496          acute respiratory infection  Concept\n",
       "497           primary pulmonary lymphoma  Concept\n",
       "498    psychoactive substance dependence  Concept\n",
       "499                     renal blood flow  Concept\n",
       "\n",
       "[500 rows x 2 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_en_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_name = '../../SemEval2018-Task9/custom_datasets/train.pickle'\n",
    "\n",
    "with open(train_name, 'wb') as f:\n",
    "    pickle.dump(train, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.read_edgelist(\"../data/only_en_wordnet.edgelist\", delimiter=\"\\t\", create_using=nx.DiGraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = Leafer(G)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parent\n",
      "Child\n",
      "WIKI:EN:daylight_saving_time\n",
      "WIKI:EN:capillary_hemangioma\n",
      "predict_hypernym 40406 40406\n"
     ]
    }
   ],
   "source": [
    "train_wnet, test_wnet = l.split_train_test(\n",
    "    generation_depth=3,  # до какого уровня в топ. сортировке идти\n",
    "    p=0.0,  # вероятность что подходящий случай уйдет в тест\n",
    "    p_divide_leafs=0.5,\n",
    "    # вероятность что листья поделим пополам трейн-тест\n",
    "    # а не засунем целый случай в трейн или в тест\n",
    "    min_to_test_rate=0.5,\n",
    "    # минимальное количество доли вершин которых не было в\n",
    "    # трейне чтобы поделить пополам на трейн-тест\n",
    "    # то есть если 6\\10 вершин были трейне то значит все 10 в трейн\n",
    "    # если 5\\10 были в трейне, то значит оставшиеся можем кинуть в тест\n",
    "    weights=[0.00, 0.0, 0.0, 0.00, 0.00, 1.],\n",
    "    # веса в соответствии\n",
    "    # один ребенок, только листья, не только листья\n",
    "    # триплеты с 2 родителями, триплеты такие что мидл нода имеет\n",
    "    # 1 ребенка,\n",
    "    #p_parent=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_verteces = [elem['children'] for elem in test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "for elem in train_wnet:\n",
    "    if elem['children'].split('.')[0] in test_verteces:\n",
    "        counter += 1\n",
    "        train_wnet.remove(elem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_augmented = train_wnet + train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(train_augmented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_augmented_name = '../../SemEval2018-Task9/custom_datasets/train_with_wnet_with_subsets.pickle'\n",
    "\n",
    "with open(train_augmented_name, 'wb') as f:\n",
    "    pickle.dump(train_augmented, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
