{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from leafer import Leafer\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import glob\n",
    "\n",
    "\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class EnrichMeanReciprocalRank:\n",
    "    \"\"\"\n",
    "     Score is reciprocal of the rank of the first relevant item\n",
    "    First element is 'rank 1'.  Relevance is binary (nonzero is relevant).\n",
    "    Example from http://en.wikipedia.org/wiki/Mean_reciprocal_rank\n",
    "    Args:\n",
    "        r: Relevance scores (list or numpy) in rank order\n",
    "            (first element is the first item)\n",
    "    Returns:\n",
    "        Mean reciprocal rank\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def __call__(self, pred_hyps, gold_hyps, r, *args):\n",
    "\n",
    "        mean_mrr = 0\n",
    "        for gold in gold_hyps:\n",
    "            if gold in pred_hyps:\n",
    "                rank = pred_hyps.index(gold)\n",
    "                lefter_positive = sum(r[:rank])\n",
    "                mean_mrr += 1/(rank + 1 - lefter_positive)\n",
    "\n",
    "        return mean_mrr / len(gold_hyps)\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"MRR\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[] 0\n",
      "a\n",
      "[1, 0] 1\n",
      "b\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "limit = 15\n",
    "golds = ['a', 'b']\n",
    "preds = ['a', 'c', 'b', 'd']\n",
    "\n",
    "r = [0 for i in range(limit)]\n",
    "\n",
    "for j in range(min(len(preds), limit)):\n",
    "    pred_hyp = preds[j]\n",
    "    if pred_hyp in golds:\n",
    "        r[j] = 1\n",
    "\n",
    "metric = EnrichMeanReciprocalRank()\n",
    "metric(preds, golds, r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "total_test = []\n",
    "\n",
    "subsets = ['1A.english', '2A.medical', '2B.music']\n",
    "for subset in subsets:\n",
    "\n",
    "    data_path = '../../SemEval2018-Task9/test/data/' + subset + '.test.data.txt'\n",
    "    gold_path = '../../SemEval2018-Task9/test/gold/' + subset + '.test.gold.txt'\n",
    "    train_data_en_data = pd.read_csv(\n",
    "                    data_path, header=None, sep=\"\\t\", names=[\"term\", \"relation\"]\n",
    "                )\n",
    "    train_gold_en_data = pd.read_csv(gold_path, header=None, names=[\"hypernym\"])\n",
    "\n",
    "    df = pd.concat([train_data_en_data, train_gold_en_data], axis=1)[\n",
    "        [\"term\", \"hypernym\"]\n",
    "    ]\n",
    "\n",
    "    test = []\n",
    "\n",
    "    for elem in df.iterrows():\n",
    "        idx, row = elem\n",
    "\n",
    "        elem = {}\n",
    "        elem[\"children\"] = row['term']\n",
    "        elem[\"parents\"] = row['hypernym'].split('\\t')\n",
    "        elem[\"grandparents\"] = None\n",
    "        elem[\"case\"] = \"predict_multiple_hypernyms\"\n",
    "\n",
    "        test.append(elem)\n",
    "\n",
    "    total_test += test\n",
    "\n",
    "    test_name = '../../SemEval2018-Task9/custom_datasets/' + subset + '.pickle'\n",
    "\n",
    "    # with open(test_name, 'wb') as f:\n",
    "    #     pickle.dump(test, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_name = '../../SemEval2018-Task9/custom_datasets/test_it.pickle'\n",
    "\n",
    "with open(test_name, 'wb') as f:\n",
    "    pickle.dump(test, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../SemEval2018-Task9/training/data/1A.english.training.data.txt\n",
      "../../SemEval2018-Task9/training/data/2A.medical.training.data.txt\n",
      "../../SemEval2018-Task9/training/data/2B.music.training.data.txt\n"
     ]
    }
   ],
   "source": [
    "# data_path = '../../SemEval2018-Task9/training/data/1A.english.training.data.txt'\n",
    "# gold_path = '../../SemEval2018-Task9/training/gold/1A.english.training.gold.txt'\n",
    "\n",
    "# train_data_en_data = pd.read_csv(\n",
    "#                 data_path, header=None, sep=\"\\t\", names=[\"term\", \"relation\"]\n",
    "#             )\n",
    "# train_gold_en_data = pd.read_csv(gold_path, header=None, names=[\"hypernym\"])\n",
    "\n",
    "# df = pd.concat([train_data_en_data, train_gold_en_data], axis=1)[\n",
    "#     [\"term\", \"hypernym\"]\n",
    "# ]\n",
    "\n",
    "total_train = []\n",
    "\n",
    "subsets = ['1A.english', '2A.medical', '2B.music']\n",
    "for subset in subsets:\n",
    "\n",
    "    data_path = '../../SemEval2018-Task9/training/data/' + subset + '.training.data.txt'\n",
    "    gold_path = '../../SemEval2018-Task9/training/gold/' + subset + '.training.gold.txt'\n",
    "    print(data_path)\n",
    "    train_data_en_data = pd.read_csv(\n",
    "                    data_path, header=None, sep=\"\\t\", names=[\"term\", \"relation\"]\n",
    "                )\n",
    "    train_gold_en_data = pd.read_csv(gold_path, header=None, names=[\"hypernym\"])\n",
    "\n",
    "    df = pd.concat([train_data_en_data, train_gold_en_data], axis=1)[\n",
    "        [\"term\", \"hypernym\"]\n",
    "    ]\n",
    "\n",
    "    train = []\n",
    "\n",
    "    for elem in df.iterrows():\n",
    "        idx, row = elem\n",
    "\n",
    "        elem = {}\n",
    "        elem[\"children\"] = row['term']\n",
    "        elem[\"parents\"] = row['hypernym'].split('\\t')\n",
    "        elem[\"grandparents\"] = None\n",
    "        elem[\"case\"] = \"predict_multiple_hypernyms\"\n",
    "\n",
    "        train.append(elem)\n",
    "\n",
    "    total_train += train\n",
    "\n",
    "    train_name = '../../SemEval2018-Task9/custom_datasets/' + subset + '_train.pickle'\n",
    "\n",
    "    with open(train_name, 'wb') as f:\n",
    "        pickle.dump(train, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/LLM_Taxonomy/SemEval2018-Task9/custom_datasets/2A.medical_train.pickle', 'rb') as f:\n",
    "    train = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('../../pipeline_src/')\n",
    "from dataset.prompt_schemas import predict_multiple_parents_from_child"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "for obj in train:\n",
    "    predict_multiple_parents_from_child(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'children': nan,\n",
       " 'parents': ['function', 'renal function', 'blood flow', 'flow'],\n",
       " 'grandparents': None,\n",
       " 'case': 'predict_multiple_hypernyms'}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = '2A.medical'\n",
    "data_path = '../../SemEval2018-Task9/training/data/' + subset + '.training.data.txt'\n",
    "\n",
    "train_data_en_data = pd.read_csv(\n",
    "                data_path, header=None, sep=\"\\t\", names=[\"term\", \"relation\"]\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>relation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bone spur</td>\n",
       "      <td>Concept</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>endodontics</td>\n",
       "      <td>Concept</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>recurrent cancer</td>\n",
       "      <td>Concept</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>neurohypophyseal diabetes insipidus</td>\n",
       "      <td>Concept</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fixed orthodontic appliance</td>\n",
       "      <td>Concept</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>continuous blood sampling</td>\n",
       "      <td>Concept</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>acute respiratory infection</td>\n",
       "      <td>Concept</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>primary pulmonary lymphoma</td>\n",
       "      <td>Concept</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>psychoactive substance dependence</td>\n",
       "      <td>Concept</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>renal blood flow</td>\n",
       "      <td>Concept</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    term relation\n",
       "0                              bone spur  Concept\n",
       "1                            endodontics  Concept\n",
       "2                       recurrent cancer  Concept\n",
       "3    neurohypophyseal diabetes insipidus  Concept\n",
       "4            fixed orthodontic appliance  Concept\n",
       "..                                   ...      ...\n",
       "495            continuous blood sampling  Concept\n",
       "496          acute respiratory infection  Concept\n",
       "497           primary pulmonary lymphoma  Concept\n",
       "498    psychoactive substance dependence  Concept\n",
       "499                     renal blood flow  Concept\n",
       "\n",
       "[500 rows x 2 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_en_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_name = '../../SemEval2018-Task9/custom_datasets/train.pickle'\n",
    "\n",
    "with open(train_name, 'wb') as f:\n",
    "    pickle.dump(train, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.read_edgelist(\"../data/only_en_wordnet.edgelist\", delimiter=\"\\t\", create_using=nx.DiGraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = Leafer(G)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parent\n",
      "Child\n",
      "WIKI:EN:daylight_saving_time\n",
      "WIKI:EN:capillary_hemangioma\n",
      "predict_hypernym 40406 40406\n"
     ]
    }
   ],
   "source": [
    "train_wnet, test_wnet = l.split_train_test(\n",
    "    generation_depth=3,  # до какого уровня в топ. сортировке идти\n",
    "    p=0.0,  # вероятность что подходящий случай уйдет в тест\n",
    "    p_divide_leafs=0.5,\n",
    "    # вероятность что листья поделим пополам трейн-тест\n",
    "    # а не засунем целый случай в трейн или в тест\n",
    "    min_to_test_rate=0.5,\n",
    "    # минимальное количество доли вершин которых не было в\n",
    "    # трейне чтобы поделить пополам на трейн-тест\n",
    "    # то есть если 6\\10 вершин были трейне то значит все 10 в трейн\n",
    "    # если 5\\10 были в трейне, то значит оставшиеся можем кинуть в тест\n",
    "    weights=[0.00, 0.0, 0.0, 0.00, 0.00, 1.],\n",
    "    # веса в соответствии\n",
    "    # один ребенок, только листья, не только листья\n",
    "    # триплеты с 2 родителями, триплеты такие что мидл нода имеет\n",
    "    # 1 ребенка,\n",
    "    #p_parent=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = '../../SemEval2018-Task9/custom_datasets/1A.english.pickle'\n",
    "with open(test_path, 'rb') as f:\n",
    "    test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_verteces = [elem['children'] for elem in test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "for elem in train_wnet:\n",
    "    if elem['children'].split('.')[0] in test_verteces:\n",
    "        counter += 1\n",
    "        train_wnet.remove(elem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "246"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_augmented_name = '../../SemEval2018-Task9/custom_datasets/only_wnet_train.pickle'\n",
    "\n",
    "with open(train_augmented_name, 'wb') as f:\n",
    "    pickle.dump(train_wnet, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_augmented = train_wnet + train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(train_augmented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_augmented_name = '../../SemEval2018-Task9/custom_datasets/train_with_wnet_with_subsets.pickle'\n",
    "\n",
    "with open(train_augmented_name, 'wb') as f:\n",
    "    pickle.dump(train_augmented, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
