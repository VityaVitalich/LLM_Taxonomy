SEED:
  - 0
CUDA_VISIBLE_DEVICES:
  - 1
  - 6
  - 3
  - 4
EPOCHS:
  - 4
BATCH_SIZE:
  - 2
LR:
  - 3e-4
MIN_LR:
  - 3e-6
DATA_PATH:
  - "babel_datasets/wnet_train_en_babel.pickle"
TEST_DATA_PATH:
  - "babel_datasets/wnet_test_en_babel.pickle"
USING_PEFT:
  - True
MODEL_TYPE:
  - Llama
MODEL_CHECKPOINT:
  - "decapoda-research/llama-30b-hf"
DTYPE:
- "full"
LOG_PRED_EVERY:
- 400
DATA_PREPROC_STYLE:
- "remove_all_from_labels"
LOAD_PATH:
- "decapoda-research-llama-30b-hfreweighted_wnet_remove_all_from_labels_custom_multilang_epoch=0_MAP=0.15165570588873462.pth"
PREV_PREDICT:
- _decapoda-research-llama-30b-hfremove_all_from_labels_stohastic_
STRATEGY:
- "stohastic"
NUM_BEAMS:
- 8
MAX_NEW_TOKENS:
- 36
TEMPERATURE:
- 0.95
TOP_K:
- 20
NUM_RETURN_SEQUENCES:
- 5
QLORA:
- true